{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Systems & Future Directions\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "By the end of this class you should be to:\n",
    "---\n",
    "\n",
    "- Describe the workflow for Data Science products\n",
    "- Be inspired to check out tensors and deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Data Science Workflow\n",
    "---\n",
    "\n",
    "![](images/crispdm_process_diagram.png)\n",
    "Cross-Industry Standard Process for Data Mining (CRISP-DM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "My Data Science Workflow\n",
    "---\n",
    "\n",
    "1. Ask\n",
    "2. Acquire\n",
    "3. Process\n",
    "4. Model\n",
    "5. Deliver\n",
    "\n",
    "[Specific example here](http://www.slideshare.net/foco24/a-data-science-workflow-nonprofit-edition)\n",
    "\n",
    "People, especially data scientist, over-focus on the modeling step. For example, we have 2 (or more classes) on modeling but no dedicated class for processing or delivering.\n",
    "\n",
    "You will have to repeat each step many times, thus it makes sense to create a pipeline that automatic building of each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Data Science Project Management 101\n",
    "---\n",
    "\n",
    "<img src=\"http://img.pandawhale.com/KBP1hI-software-engineering-tree-swin-pDYw.jpeg\" style=\"width: 400px;\"/>\n",
    "\n",
    "> Do the simplest thing that could possibly work\n",
    "\n",
    "[Core tenet of Agile](http://c2.com/cgi-bin/wiki?DoTheSimplestThingThatCouldPossiblyWork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Satisfy the customer through early and continuous delivery of valuable software\n",
    "\n",
    "[Delivering Data Science](https://github.com/ianozsvald/data_science_delivered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"http://ichef.bbci.co.uk/news/660/media/images/62558000/jpg/_62558092_15.thecountand8-richardtermine.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "> Data science is mostly counting and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Check for understanding\n",
    "---\n",
    "\n",
    "<details><summary>\n",
    "Why is Data Science mostly counting and logistic regression?\n",
    "</summary>\n",
    "If you don't have counts correct, you can't do anything else. When you have counts (especially lots of counts), you can fit models.\n",
    "<br>\n",
    "Logistic regression is just binary linear model. Simple to calculate and interpret.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Visualizations: The alapha and omega of data\n",
    "----\n",
    "\n",
    "![](images/pie.jpg)\n",
    "\n",
    "Visualizations are way to understand raw data, modeling results, and to communicate to people.\n",
    "\n",
    "[A collection of text visualizations](http://textvis.lnu.se/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "NL is a great UI\n",
    "---\n",
    "\n",
    "![](http://static.boredpanda.com/blog/wp-content/uploads/2015/11/poor-design-decisions-481__605.jpg)\n",
    "Design is important\n",
    "\n",
    "We use NL every day to communicate with each other. In the future, we'll use it to communicate more and more with computers. It is artificial that we have to type and use screens. UI will evolve to become transparent. NLP will be a force multiplier for that transition\n",
    "\n",
    "As an intermediate step chat interface. It is silly that there are some many apps. I predict in the future. There will be meta-apps. That are AI chatbots that will give you information and do things for you.\n",
    "\n",
    "__Reasons to be bullish on chat at UI__:\n",
    "\n",
    "- Chat is a common interface for many APIs / IoT (the Internet of Things)\n",
    "- Every user interaction is also a survey\n",
    "- UI is testable, while the surface area of a visual interface is almost untestable\n",
    "- The UI is a log file\n",
    "\n",
    "[Chat as UI 1](http://www.wired.com/2015/06/future-ui-design-old-school-text-messages/) \n",
    "[Chat as UI 2](https://medium.com/@acroll/on-chat-as-interface-92a68d2bf854#.i9rhhfql3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "NLP algorithms: Application beyond words\n",
    "----\n",
    "\n",
    "NLP has borrowed from other disciplines (Math, Statistics, and Machine Learning). Now it is starting to give back. \n",
    "\n",
    "For example, word2vec is applied to clinical diagnosis. A research could clinical diagnosis notes to find the co-occurrence of disease and symptoms. There is too much medical research for any doctor to up on it all.\n",
    "\n",
    "Casey Stella treated discrete clinical events (i.e. Diagnoses, drugs prescribed, etc.) in a medical dataset as non-textual \"words‚Äù. He found that heart disease or hardening of the arteries is associated with \"Personal history of peptic ulcer disease\". Partially due to smokers having a higher than average incidence of peptic ulcers and atherosclerosis. \n",
    "\n",
    "In special topics, we are going to take about how probabilistic graphical models (PGMs) can be used to understand disease. \n",
    "\n",
    "[Using Natural Language Processing on Non-Textual Data with MLLib](https://www.youtube.com/watch?v=rWphXAdcoe0)   \n",
    "[Slides](http://www.slideshare.net/gpano/natural-language-processing-on-nontextual-data)   \n",
    "[Code](https://github.com/cestella/presentations/blob/master/NLP_on_non_textual_data/src/main/ipython/clinical2vec.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "What the hell is a tensor?\n",
    "---\n",
    "\n",
    "A tensor is a multidimensional array.\n",
    "\n",
    "![](images/tensor_intro.png)\n",
    "\n",
    "![](images/tensor_dim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Why tensors?\n",
    "---\n",
    "\n",
    "![](images/higher_order.png)\n",
    "\n",
    "Tensors can model higher order relationships. \n",
    "\n",
    "![](images/relationships.png)\n",
    "\n",
    "If you want to only represent pair-wise relationships, say co-occurrence of every pair of words in a set of documents, then use a matrix. On the other hand, if you want to learn the probability of a range of triplets of words, then we need a tensor to record that relationship. \n",
    "\n",
    "Tensors can extend beyond document-term matrix to document-term-year-author tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Tensors: The way of the future\n",
    "----\n",
    "\n",
    "The Data Science community is just starting to develop the wide-spread knowledge base, language, and tools to handle tensors.\n",
    "\n",
    "---\n",
    "\"Tensor Methods - A New Paradigm for Training Probabilistic Models, Neural Networks and Reinforcement Learning\"\n",
    "\n",
    "https://www.youtube.com/watch?v=YpnlAQTY1Mc\n",
    "\n",
    "http://www.slideshare.net/SessionsEvents/animashree-anandkumar-electrical-engineering-and-cs-dept-uc-irvine-at-mlconf-sf-111315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Deep Learning is eating machine learning\n",
    "----\n",
    "\n",
    "![](images/current_ml.png)\n",
    "\n",
    "![](images/future_ml.png)\n",
    "\n",
    "We spent much of the course learning how to do feature engineering. Deep learning automates much of that process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Types of neural networks\n",
    "---\n",
    "\n",
    "| Abbreviation|  Name | Description |  \n",
    "|:-------:|:------ | :------| \n",
    "| [NN](https://en.wikipedia.org/wiki/Artificial_neural_network) | Neural Network | Restricted Boltzmann with at least 1 hidden layer |\n",
    "| [CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network) | Convolutional Neural Network | Like vision, learns reoccurring features in a visual field |\n",
    "| [RNN](https://en.wikipedia.org/wiki/Recurrent_neural_network)| Recurrent Neural Network| Learns sequences through a type of short-term memory |\n",
    "| [LTSM](https://en.wikipedia.org/wiki/Long_short-term_memory) | Long short-term memory | Like RNN but can learn between long time lags | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "NLP is just Time Series disguise\n",
    "---\n",
    "\n",
    "Recurrent neural networks (RNN) are awesome!\n",
    "\n",
    "<img src=\"images/charseq.jpeg\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/rnn_unit.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "RNN learns sequences, in particular mapping of sequence-to-sequence\n",
    "\n",
    "Many challenges can be described as sequence-to-sequence.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Translation\n",
    "- Image captioning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "RNNs for NLP\n",
    "---\n",
    "\n",
    "![](http://simaaron.github.io/images/RNN_arc_2.png)\n",
    "\n",
    "2 RNNs going into different directions\n",
    "\n",
    "The forward RNN reads the input sequence from start to end, while the backward RNN reads it from end to start. \n",
    "\n",
    "The two RNNs are stacked on top of each others and their states are typically combined by appending the two vectors. \n",
    "\n",
    "![](https://devblogs.nvidia.com/wp-content/uploads/2015/07/Figure2_biRNN.png)\n",
    "\n",
    "Bidirectional RNNs are often used in Natural Language problems, where we want to take the context from both before and after a word into account before making a prediction.\n",
    "\n",
    "\n",
    "---\n",
    "Sources\n",
    "----\n",
    "[Bidirectional Recurrent Neural Networks as Generative Models](https://papers.nips.cc/paper/5651-bidirectional-recurrent-neural-networks-as-generative-models.pdf)\n",
    "- [Implementation in TensorFlow](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/bidirectional_rnn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Rap Battle with RNNs\n",
    "---\n",
    "\n",
    "<img src=\"http://orig03.deviantart.net/2ae0/f/2013/326/1/c/unit_mmlp2__the_rap_bot_by_frederickwalter-d6v5g7c.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    ">We describe an unconventional line of attack in our quest to teach machines how to rap battle by improvising hip hop lyrics on the fly, in which a novel recursive bilingual neural network, TRAAM, implicitly learns soft, context-dependent generalizations over the structural relationships between associated parts of challenge and response raps, while avoiding\n",
    "the exponential complexity costs that symbolic models would require. \n",
    "\n",
    ">TRAAM learns feature vectorssimultaneously using context from both the\n",
    "challenge and the response, such that challengeresponse association patterns with similar structure tend to have similar vectors. Improvisation is modeled as a quasi-translation learning problem, where TRAAM is trained to improvise fluent and rhyming responses to challenge lyrics.\n",
    "\n",
    "| Challenge | Model Response  |  \n",
    "|:-------:|:------:|\n",
    "| picture on the quota its time to roll | ya for a quarter i mind and soul |\n",
    "| thug deep in my soul that got me bugged | love you on the control the drugs |  \n",
    "| nights of 51 jipped be light on this cash | in the concrete mics you right in the ass |\n",
    "| what would i do | just me and you |\n",
    "| we get rid of the child | and the number and a wild |\n",
    "\n",
    "[Source](http://ijcai.org/Proceedings/15/Papers/358.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Additional Reading on Neural Networks\n",
    "---\n",
    "- [A Primer on Neural Network Models for Natural Language Processing](http://u.cs.biu.ac.il/~yogo/nnlp.pdf)\n",
    "- [Compositionality with Deep Neural Networks](https://staff.fnwi.uva.nl/e.kanoulas/wp-content/uploads/Lecture-6-2-Compositinality-with-Deep-Neural-Networks.pdf) \n",
    "- [Deep learning for NLP by Standford](http://cs224d.stanford.edu/)\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "NLP skills are in high demand\n",
    "----\n",
    "\n",
    "![](images/desperate_recruiter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Summary\n",
    "---\n",
    "\n",
    "- Always be adding value. Think about your work.\n",
    "- Keep one eye on the future: chat, visualization, tensors, and deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
