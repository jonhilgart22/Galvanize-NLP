{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Exercise: Text Classification for Sentiment Analysis\n",
    "===\n",
    "\n",
    "![](http://choyeski.com/wp-content/uploads/2013/02/movie-review.jpg)\n",
    "\n",
    "\n",
    "Let's pick where we left off last session...\n",
    "\n",
    "Let's refine the best model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews = load_files('/Users/jonathanhilgart/DSCI6004-student/week_5/5_2_classification_naive_bayes/review_polarity/txt_sentoken/', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(reviews.data,reviews.target,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "count.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_cv = count.transform(X_train)\n",
    "\n",
    "X_test_cv = count.transform(X_test)\n",
    "\n",
    "y_test_cv = y_test\n",
    "y_train_cv = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multiNB = MultinomialNB()\n",
    "multiNB.fit(X_train_cv,y_train_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Calcute the precision on the test data\n",
    "\n",
    "<br>\n",
    "<details><summary>\n",
    "Click here for the precision score...\n",
    "</summary>\n",
    "<br>\n",
    "85.65%\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for Count Vectorizer with Multi Naive Bayes 84.54%\n"
     ]
    }
   ],
   "source": [
    "#Precision Score from Count Vectorizer with MNB\n",
    "print('Precision score for Count Vectorizer with Multi Naive Bayes {:.2%}'.format(precision_score(y_test_cv,multiNB.predict(X_test_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "X_train_tf = tfidf.transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "y_train_tf = y_train\n",
    "y_test_tf = y_test\n",
    "multiNB_tf = MultinomialNB()\n",
    "multiNB_tf.fit(X_train_tf,y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for TF-IDF with Multi Naive Bayes 85.47%\n"
     ]
    }
   ],
   "source": [
    "#Precision Score from TF-IDF with MNB\n",
    "print('Precision score for TF-IDF with Multi Naive Bayes {:.2%}'.format(precision_score(y_test_tf,multiNB_tf.predict(X_test_tf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Calcute the recall on the test data\n",
    "\n",
    "<br>\n",
    "<details><summary>\n",
    "Click here for the recall score...\n",
    "</summary>\n",
    "<br>\n",
    "78.38%\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall socre for Count Vectorizer with Multi Naive Bayes 82.27%\n"
     ]
    }
   ],
   "source": [
    "print('Recall socre for Count Vectorizer with Multi Naive Bayes {:.2%}'.format(recall_score(y_test_cv,multiNB.predict(X_test_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall socre for TF-IDF with Multi Naive Bayes 75.37%\n"
     ]
    }
   ],
   "source": [
    "print('Recall socre for TF-IDF with Multi Naive Bayes {:.2%}'.format(recall_score(y_test_tf,multiNB_tf.predict(X_test_tf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think one is so much higher than the other?\n",
    "\n",
    "What does that tell us about our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This recall score is much higher for Count Vectorizer.\n",
    "# This is probably because the frequency of words is the best indicator of which documents we should retreive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "Calcute the $F_1$ score \n",
    "\n",
    "<br>\n",
    "<details><summary>\n",
    "Click here for the $F_1$ score...\n",
    "</summary>\n",
    "<br>\n",
    "$F_1$ = 80.86%\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Count Vectorizer with Multi Naive Bayes 80.87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1 score for Count Vectorizer with Multi Naive Bayes {:.2%}'.format(f1_score(y_test_cv,multiNB.predict(X_test_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for TF-IDF with Multi Naive Bayes 80.10%\n"
     ]
    }
   ],
   "source": [
    "print('F1 score for TF-IDF with Multi Naive Bayes {:.2%}'.format(f1_score(y_test_tf,multiNB_tf.predict(X_test_tf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the best way to summarize your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This best way to summarzie your model if using a F1 score because this takes into account both Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "How could you improve your $F_1$ score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Either increase precision, increase recall, or both. You could do this by adding addition variables, such as variable\n",
    "#interactions, into your dataset. Maybe adding in bigrams and trigrams would be helpful.  POS as well possibly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Let's experiment with another sentiment tool: [TextBlob](https://textblob.readthedocs.org/en/dev/quickstart.html#sentiment-analysis)\n",
    "\n",
    "It comes pretrained..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.35, subjectivity=0.7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roger Ebert hatin' http://www.rogerebert.com/reviews/north-1994\n",
    "\n",
    "testimonial = TextBlob(\"\"\"I have no idea why Rob Reiner, or anyone else, wanted to make this story into a movie, and close examination of the film itself is no help. \n",
    "\"North\" is one of the most unpleasant, contrived, artificial, cloying experiences I've had at the movies. \n",
    "To call it manipulative would be inaccurate; it has an ambition to manipulate, but fails\"\"\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit TextBlob to the moview reviews. - I used Logistic Regression here to take into account the negative polarity measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data =[[np.array(TextBlob(str(review)).sentiment[0]),np.array(TextBlob(str(review)).sentiment[1]),np.array(target)] for review,target in zip(reviews.data, reviews.target)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment,polarity, actual =zip(*data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = np.vstack((sentiment, polarity)).T\n",
    "np.shape(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02187671,  0.47086754],\n",
       "       [ 0.24288095,  0.5815    ],\n",
       "       [ 0.1469898 ,  0.56258503],\n",
       "       ..., \n",
       "       [ 0.09856043,  0.44569848],\n",
       "       [ 0.02472222,  0.52404321],\n",
       "       [ 0.15193284,  0.63966353]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent =train_test_split(total_data,actual,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 1)\n",
      "(1600,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_sent,y_train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to use logistic regression because of the negative values in polarity. Naive Bayes assumes Binomial distribution\n",
    "#which is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Logistc Regression with  and Textblob sentiment 70.68%\n"
     ]
    }
   ],
   "source": [
    "print('F1 score for Logistc Regression with  and Textblob sentiment {:.2%}'.format(f1_score(y_test_sent,logit.predict(X_test_sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score for Textblob sentiment with Logistic Regression 75.42%\n"
     ]
    }
   ],
   "source": [
    "print('Recall score for Textblob sentiment with Logistic Regression {:.2%}'.format(recall_score(y_test_sent,logit.predict(X_test_sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for Textblob sentiment with Logistic Regression 66.50%\n"
     ]
    }
   ],
   "source": [
    "print('Precision score for Textblob sentiment with Logistic Regression {:.2%}'.format(precision_score(y_test_sent,logit.predict(X_test_sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Naive Bayes\n",
    "data_sentiment = [0 if TextBlob(str(review)).sentiment[0]<=0 else 1 for review  in reviews.data  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s =train_test_split(np.array(data_sentiment),np.array(reviews.target),test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_s = X_train_s.reshape(-1,1)\n",
    "y_train_x = y_train_s.reshape(-1,1)\n",
    "X_test_s = X_test_s.reshape(-1,1)\n",
    "y_test_s = y_test_s.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_MNB = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_MNB.fit(X_train_s,y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for MNB with  and Textblob sentiment 63.25%\n",
      "Recall score for Textblob sentiment with MNB 100.00%\n",
      "Precision score for Textblob sentiment with MNB 46.25%\n"
     ]
    }
   ],
   "source": [
    "print('F1 score for MNB with  and Textblob sentiment {:.2%}'.format(f1_score(y_test_s,sentiment_MNB.predict(X_test_s))))\n",
    "print('Recall score for Textblob sentiment with MNB {:.2%}'.format(recall_score(y_test_s,sentiment_MNB.predict(X_test_s))))\n",
    "print('Precision score for Textblob sentiment with MNB {:.2%}'.format(precision_score(y_test_s,sentiment_MNB.predict(X_test_s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train TextBlob..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    (\"What an awesome view\", 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    (\"I ain't feeling dandy today.\", 'neg'),\n",
    "    (\"I feel amazing!\", 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was good.\n",
      "  gold: \t pos\n",
      "  predicted: \t pos\n",
      "\n",
      "I do not enjoy my job\n",
      "  gold: \t neg\n",
      "  predicted: \t neg\n",
      "\n",
      "I ain't feeling dandy today.\n",
      "  gold: \t neg\n",
      "  predicted: \t neg\n",
      "\n",
      "I feel amazing!\n",
      "  gold: \t pos\n",
      "  predicted: \t pos\n",
      "\n",
      "Gary is a friend of mine.\n",
      "  gold: \t pos\n",
      "  predicted: \t neg\n",
      "\n",
      "I can't believe I'm doing this.\n",
      "  gold: \t neg\n",
      "  predicted: \t neg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, label in test:\n",
    "    print(review)\n",
    "    print(\"  gold: \\t\", label)\n",
    "    print(\"  predicted: \\t\", cl.classify(review))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2}\".format(cl.accuracy(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"Their burgers are amazing\")  # \"pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify(\"I don't like their pizza.\") # neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n",
      "             contains(I) = True              neg : pos    =      1.4 : 1.0\n",
      "         contains(place) = False             neg : pos    =      1.2 : 1.0\n",
      "         contains(enemy) = False             pos : neg    =      1.2 : 1.0\n",
      "         contains(these) = False             neg : pos    =      1.2 : 1.0\n",
      "         contains(beers) = False             neg : pos    =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train TextBlob on the moview reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "sentiment = load_files('/Users/jonathanhilgart/DSCI6004-student/week_5/\\\n",
    "5_2_classification_naive_bayes/review_polarity/txt_sentoken/', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_mnb, X_test_mnb, y_train_mnb, y_test_mnb =train_test_split(sentiment.data,sentiment.target,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c2 = NaiveBayesClassifier(zip(X_train_mnb,y_train_mnb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for MNB with Multi Naive Bayes and Textblob sentiment 66.89%\n",
      "Recall score for MNB with Multi Naive Bayes 100.00%\n",
      "Precision score for MNB with Multi Naive Bayes 50.25%\n"
     ]
    }
   ],
   "source": [
    "print('F1 score for MNB with Multi Naive Bayes and Textblob sentiment {:.2%}'.format(f1_score(y_test_mnb,[c2.classify(i) for i in X_test_mnb])))\n",
    "\n",
    "print('Recall score for MNB with Multi Naive Bayes {:.2%}'.format(recall_score(y_test_mnb,[c2.classify(i) for i in X_test_mnb])))\n",
    "print('Precision score for MNB with Multi Naive Bayes {:.2%}'.format(precision_score(y_test_mnb,[c2.classify(i) for i in X_test_mnb])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model would you deploy for a moview review site? Think about performance, speed, and ease of use.\n",
    "\n",
    "For example, [Rotten Tomatoes](https://www.rottentomatoes.com/m/battlefield_earth/) shows postive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the raw text with a Naive Bayes classifier works better than MNB distribution on polarity data.\n",
    "# Naive Bayes if faster and easier to use. I would go with the Naive Bayes approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Challenge exercises\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features for negation\n",
    "\n",
    "Let's model negation as shown in the videos by adding `NOT_` to every word between negation and following punctuation:  \n",
    "    $e.g.$ `\"didn’t like this movie , but I\"`  \n",
    "    $\\rightarrow$ `\"didn’t NOT_like NOT_this NOT_movie but I\"`  \n",
    "\n",
    "See [Stack Overflow](http://stackoverflow.com/questions/23384351/how-to-add-tags-to-negated-words-in-strings-that-follow-not-no-and-never) for how an example of how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does adding negation improve your overall performance as measured in confusion matrix? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try other modes and hyperparameters. \n",
    "\n",
    "Can you find a model with higher F1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
