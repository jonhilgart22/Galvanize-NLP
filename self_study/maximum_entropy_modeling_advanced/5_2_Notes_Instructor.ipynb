{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2\n",
    "===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agenda\n",
    "---------------------\n",
    "1. OYO\n",
    "2. Review\n",
    "3. RAT\n",
    "4. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "----\n",
    "- Maximum Entropy Model\n",
    "- Information Theory sidebar\n",
    "    - Entropy - uncertainity\n",
    "    - Max entropy - uniform\n",
    "    - Min entorpy - impluse/ Dirac delta function\n",
    "    - surprise log(1/probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dirac delta function](images/dirac_function.png)\n",
    "cotinous but a single point\n",
    "\n",
    "![Uniform function](images/Uniform_Distribution.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxEnt modeling: maximize entropy, given constraints generated from features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume uniform (max entropy), unless we have data. Then we use the data to change our model of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxEnt Example\n",
    "----\n",
    "\n",
    "Uniform Prior:\n",
    "    PERSON = .5\n",
    "    ORGANIZATION = .5\n",
    "\n",
    "Data counts:\n",
    "    PERSON = 50\n",
    "    ORGANIZATION = 10\n",
    "\n",
    "Add feature:\n",
    "    PERSON is 5x more likely than ORGANIZATION\n",
    "\n",
    "Updated Prior:\n",
    "    PERSON = 0.833\n",
    "    ORGANIZATION = 0.166\n",
    "\n",
    "****\n",
    "More Data:\n",
    "PERSON_CLEB_FALSE = 100\n",
    "PERSON_CLEB_TRUE = 10\n",
    "\n",
    "Add feature:\n",
    "    PERSON_CLEB_FALSE is 10x more likely than PERSON_CLEB_TRUE\n",
    "\n",
    "![](images/update.jpg)\n",
    "Updated Prior:\n",
    "    PERSON = 0.833\n",
    "        PERSON_CLEB_FALSE = 0.757\n",
    "        PERSON_CLEB_TRUE = 0.0757 \n",
    "    ORGANIZATION = 0.166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxEnt is Convex.\n",
    "\n",
    "Convexity is easy day. Linear supspaces!\n",
    "\n",
    "***\n",
    "\n",
    "Contrast to Naive Bayes, no double counting\n",
    "\n",
    "Condtionaly probablities See above\n",
    "\n",
    "Minimize duplicate weighting but More features (feature enigeering) \n",
    "\n",
    "\n",
    "***\n",
    "features:\n",
    "- single items\n",
    "- previous word and next word\n",
    "\n",
    "__REMEMBER__: Get lots of data for each feature (including conditonal features)!\n",
    "\n",
    "***\n",
    "\n",
    "HT Novig [Part I](http://nbviewer.ipython.org/url/norvig.com/ipython/xkcd1313.ipynb?create=1)\n",
    "[Part II](http://nbviewer.ipython.org/url/norvig.com/ipython/xkcd1313-part2.ipynb?create=1)\n",
    "\n",
    "Greedy is \"good enough\"\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing\n",
    "---\n",
    "\n",
    "Avoid overfitting\n",
    "Smooothing is regulariztion. \n",
    "\n",
    "Issues:\n",
    "- Too many features\n",
    "- Sparsity\n",
    "- Infinite weights\n",
    "\n",
    "Reduce dependence of features by abstracting out\n",
    "(e.g., model the difference of two dependent features, head and tails)\n",
    "\n",
    "early stopping \"good enough\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP\n",
    "---\n",
    "Maximum A Posteriori (MAP) estimation\n",
    "\n",
    "Smooth paramters (evidence never completely domintates prior)\n",
    "\n",
    "> We can also derive a point estimate. For example, the maximum a posteriori (MAP) estimation consists in considering the maximum of this distribution as an estimate for q. We can find this maximum analytically or numerically. Here, we find analytically q̂ =h/n, which looks quite sensible. \n",
    "\n",
    "Use all the information (weighted)\n",
    "\n",
    "\n",
    "[Example](http://stats.stackexchange.com/questions/65212/example-of-maximum-a-posteriori-estimation)\n",
    "[Example](https://github.com/unpingco/Python-for-Signal-Processing/blob/master/MAP_Estimation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between Maximum Likelihood (ML) and Maximum a Posteri (MAP) estimation?\n",
    "\n",
    "The maximum likelihood estimate (MLE) of a parameter is the value of the parameter that maximizes the likelihood, where the likelihood is a function of the parameter and is actually equal to the probability of the data conditioning on that parameter. \n",
    "\n",
    "Maximum a posteriori (MAP) estimation is the value of the parameter that maximizes the entire posterior distribution (which is calculated using the likelihood). A MAP estimate is the mode of the posterior distribution. \n",
    "\n",
    "Note that there is no difference between the MLE and the MAP estimate if the prior distribution we were assuming was a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Intro of MaxEnt](http://cmm.cit.nih.go`av/maxent`/letsgo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAT Solutions\n",
    "----\n",
    "1. 1/8, 1/4, 1/8, 1/4, 1/8, 1/8 \n",
    "2. A) Computing the expectation...\n",
    "4. C. Prior distribution is assumed to be a constant. ML only use the observed data. MAP incorprates the prior. if the pior is contant they will be the same.\n",
    "5. Define add-one smoothing in Plain English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra RAT\n",
    "----\n",
    "\n",
    "2) Suppose we have a 1 feature maxent model built over observed data as shown. This time our one feature is picking out little b. Work out what the expectation of that feature is and choose the constructed model's probability distribution over the four possible outcomes.\n",
    "\n",
    "|\t| ends-with(vowel)\t| ends-with(constant) |\n",
    "|:- | :--:| :-:|\n",
    "| starts-with(capital)\t| 1\t| 1\t|\n",
    "| starts-with(lower)\t| 2\t| 2\t|\n",
    "\n",
    "$$f=\\{\\text{ends-with(vowel)}\\}$$\n",
    "\n",
    "> 1/4, 1/4, 1/4, 1/4\n",
    "\n",
    "4) Suppose a certain feature $f_i$ matches 4 times over the training data (C,D). That is, it's empirical expectation is 4. Suppose further that we train a smoothed maxent model with σ2=1 and that the feature gets a weight of λi=1 in the resulting model. What will the empirical expectation of the feature on the training data D be?\n",
    "\n",
    ">For an unsmoothed maxent model, the model expectation of a feature over the training data will equal its empirical expectation (the count of the number of times the feature fires over (C,D), here 4). However, when the model is smoothed, the model expectation will be discounted. The partial derivative on the previous slide will still be zero at the maximum of the function, but since λ/σ2=1/1, the partial derivative will be zero when the model expectation is 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
