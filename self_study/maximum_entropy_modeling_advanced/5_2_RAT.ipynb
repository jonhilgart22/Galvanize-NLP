{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 RAT\n",
    "===\n",
    "\n",
    "1) Let's say we have the following event space and the empirical data:  \n",
    "\n",
    "| VB | VBD | VBG | VBN | VBP |VBZ|\n",
    "|:-------:|:------:|:------:|:------:|:------:|:------:|\n",
    "| 5 | 10 | 4 | 8 | 6 | 7 |\n",
    "\n",
    "What will be the probability distribution that maximize entropy with the following feature?\n",
    "$$f_{past}=\\{\\text{VBD, VBN}\\}, E[f_{past}]=1/2$$\n",
    "\n",
    "2) Which of the following is __not__ true of joint models P(c, d) with the marginal constraint? <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; A) Computing the expectation of each feature is more time-consuming with the marginal constraint <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; B) P(c,d) is zero if d does not occur in our empirical data <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; C) Maximizing P(c,d) is equivalent to maximizing P(c|d) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; D) The model is useful when the space CÃ—D is too huge to enumerate <br>\n",
    "\n",
    "3) When are ML and the MAP estimates guaranteed to be the same?<br>\n",
    "  (pick all that apply)<br>\n",
    "  A. They are always the same.<br>\n",
    "  B. They are never the same.<br>\n",
    "  C. Prior distribution is assumed to be a constant.<br>\n",
    "  D. Prior distrubion is assumed to be normally distributed.<br>\n",
    "  E. The data is constast.<br>\n",
    "  F. The data is normally distrbuted.<br>\n",
    "  \n",
    "4) Define add-one smoothing in Plain English."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
