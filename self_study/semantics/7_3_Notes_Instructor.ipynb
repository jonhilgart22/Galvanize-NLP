{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-3 Semantics\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agenda\n",
    "---------------------\n",
    "0. OYO\n",
    "1. Review\n",
    "2. RAT\n",
    "4. Exercise Work Session "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "-----\n",
    "\n",
    "> \"You shall now a word by the company it keeps!\"\n",
    "> - Firth\n",
    "\n",
    "__Glossary__:\n",
    "- lemma - base/root form, extreme stem\n",
    "- wordform - string literal in text\n",
    "- word - either lemma or wordform\n",
    "- sense - aka word sense, separate representation of meaning\n",
    "- Homonym - \"same\"+\"form\" __but__ distinict meaning\n",
    "- Metonymy \n",
    "    - systematic relationship between senses (e.g., )\n",
    "    - the substitution of the name of an attribute or adjunct for that of the thing meant\n",
    "    - formal slang\n",
    "    - eg: suit for business executive, or the track for horse racing\n",
    "\n",
    "lemma and wordform may or may not be the same\n",
    "\n",
    "Naive Bayes model works really well to classify sense within text\n",
    "    remeber Norvig example\n",
    "\n",
    "more metadata\n",
    "\n",
    "homonymy is __not__ that hard\n",
    "    - bayesian likelihood, what do most people want most the time\n",
    "    - SERP diversity, show both\n",
    "    - Expose uncertainity to user\n",
    "\n",
    "----\n",
    "\n",
    "__Context is king__\n",
    "\"No free lunch\" No universal meaning. \n",
    "What is your goal? Why is it important?\n",
    "    Define your use case and then build system. \n",
    "\n",
    "----\n",
    "\n",
    "Synonyms are __important__\n",
    "\n",
    "esp in search.\n",
    "eg: Solr, my last project at LiveCareer, made my own thersausa\n",
    "\n",
    "----\n",
    "\n",
    "Subordinate / Subordinate, again people are way into ontologies. I don't get it\n",
    "\n",
    "### Student activity: Defend ontologies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore synset with a Pythonic API\n",
    "from pattern.en.wordnet import Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dude_sn = Synset('dude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dude_sn.<TAB>\n",
    "dude_sn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds; \"the dog barked all night\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dude_sn.gloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Score\n",
    "----\n",
    "\n",
    "inverse distance\n",
    "\n",
    "HT meaning and sense book\n",
    "fun and easy read about the relationship between many fields of science\n",
    "\n",
    "Path length - walk taxonmy, assume you have a good taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20824862546219455"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dude_sn.similarity(Synset('cool'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Distributional Similarity__\n",
    "\n",
    "vectorize words\n",
    "\n",
    "![](images/word_vector.png)\n",
    "\n",
    "look at rows (instead of columns), mulitnonmial class\n",
    "\n",
    "Moar data [TODO: Instert meme]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Not Important (for this course)__:\n",
    "- zeugma test\n",
    "- antonym\n",
    "- hyponymy and hypernymy, just say sub-type or suboridante\n",
    "- information content similarity\n",
    "- resnik method\n",
    "- how to vectorize words (next week a much better way of donig this!)\n",
    "- PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAT Solutions\n",
    "---\n",
    "1. \n",
    "__B__ Polysemy<br> \n",
    "Polysemy describes the capacity for a sign (such as a word, phrase, or symbol) to have multiple meanings, usually related by contiguity of meaning within a semantic field. We can see that the two senses of the word \"newspaper\" have different, but related, meanings.\n",
    "\n",
    "__C__ metonymy<br>\n",
    "Metonymy is word or phrase that is used to stand in for another word.\n",
    "\n",
    "[Examples](http://examples.yourdictionary.com/examples-of-metonymy.html)\n",
    "\n",
    "<br>\n",
    "2. taylor_swift <br>\n",
    "justen_beber <br>\n",
    "<br>\n",
    "3. Heap's Law (not a scientfic law) proposes the number of distinct words in a document will platau as document/corpus size grows. More instance text is gathered, there will be diminishing returns in terms of discovery of the full vocabulary from which the distinct terms are drawn.\n",
    "4. ![](instructor-resources/Heaps_law_plot.png)\n",
    "$V_R$(n) = Kn$^β$\n",
    "$V_R$ is the number of distinct words in an instance text of size n. \n",
    "K and β are free parameters determined empirically.\n",
    "With English text corpora, typically K is between 10 and 100, and β is between 0.4 and 0.6.\n",
    "5. Recall is:\n",
    "- the rate at retrieving from a population (i.e., what fraction of relevant documents are succesfully queried to the user)\n",
    "- the probability that a (randomly selected) relevant document is retrieved in a search.\n",
    "- the rate of true positve clasfication over all postive (true and false) classfications, aka true positive rate or sensitivity. \n",
    "Hit is correctly retrieving or labeling a correct instance.\n",
    "Miss is failing to retrieve or label a correct example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Exercise\n",
    "----\n",
    "\n",
    "expectations for remaining time?\n",
    "\n",
    "Scrum Questions\n",
    "-----\n",
    "\n",
    "1. What did you do yesterday?\n",
    "2. What do you plan to do today?\n",
    "3. What are obstacles or rate limiters?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
