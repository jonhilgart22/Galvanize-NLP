{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Information Retrieval Exercises\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Rider or Die\n",
    "----\n",
    "\n",
    "![](http://i.telegraph.co.uk/multimedia/archive/02162/ridderhaggard_2162866i.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be improving upon a rather poorly-made information retrieval system. You will build a system to quickly retrieve documents that match queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Data \n",
    "---\n",
    "\n",
    ">“...one day a sunrise will come when we shall be among those who are lost, and then others will watch those glorious rays, and grow sad in the midst of beauty, and dream of Death in the \n",
    "full glow of arising Life!”   \n",
    "> \\- Rider Haggard\n",
    "\n",
    "Your IR system will find relevant documents among a collection of 60 short stories by the famed [Rider Haggard](http://en.wikipedia.org/wiki/H._Rider_Haggard). \n",
    "\n",
    "The training data is located in the `data/` directory under the subdirectory `RiderHaggard/`. Within this directory you will see yet another directory `raw/`. This contains the raw text files of 60 different short stories written by Rider Haggard.\n",
    "\n",
    "A set of development queries and their expected answers are in the `data/` directory, the files `queries.txt` and `solutions.txt` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Part I\n",
    "---\n",
    "\n",
    "Improve upon the IR system provided. This involves implementing:\n",
    "\n",
    "- **Inverted Index:** a mapping from words to the documents in which they occur.\n",
    "- **Boolean Retrieval:** in which you return the list of documents that contain all words in a query* \n",
    "\n",
    "You will implement and/or improve upon the following functions:\n",
    "\n",
    "- `index():` This is where you will build the inverted index. The documents will have already been read in for you at this point, so you will want to look at some of the instance variables in the class:\n",
    "    - `self.titles`\n",
    "    - `self.docs`\n",
    "    - `self.vocab`\n",
    "- `get_posting():` This function returns a list of integers (document IDs) that identifies the documents in which the word is found. This is basically just an API into your inverted index, but you must implement it in order to be evaluated fully.\n",
    "- `boolean_retrieve():` This function performs Boolean retrieval, returning a list of document IDs corresponding to the documents in which all the words in `query` occur.\n",
    "\n",
    "\n",
    "\n",
    "\\* Yes, we only support conjunctions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Evaluation\n",
    "----\n",
    "Your IR system will be evaluated on a development set of queries as well as a held-out set of queries. The queries are encoded in the file **queries.txt** and are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That code will run you IR system and test it against the development set of queries. \n",
    "\n",
    "The first time you run the code the documents will be stemmed.\n",
    "\n",
    "Then you will see the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.intersection(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = [3,4,5,7,6,4,3,2,4,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3, 3, 4, 4, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sorted(h)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = set(['a','a','a','b'])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
=======
   "execution_count": 4,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in documents...\n",
      "Already stemmed!\n",
      "Indexing...\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]  inv index\n",
      "===== Running tests =====\n",
      "Inverted Index Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
      "Boolean Retrieval Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "%run python/ir_system_part_1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in documents...\n",
      "Already stemmed!\n",
      "Indexing...\n",
      "[0, 7, 14, 25, 26, 34]  inv index\n",
      "Calculating tf-idf...\n",
      "defaultdict(<class 'int'>, {1: 1.0, 42: 1.0}) tfidf\n",
      "===== Running tests =====\n",
      "Inverted Index Test\n",
      "    Score: 0 Feedback: 0/5 Correct. Accuracy: 0.000000\n",
      "Boolean Retrieval Test\n",
      "    Score: 0 Feedback: 0/5 Correct. Accuracy: 0.000000\n",
      "TF-IDF Test\n",
      "    Score: 0 Feedback: 0/5 Correct. Accuracy: 0.000000\n",
      "Cosine Similarity Test\n",
      "    Score: 0 Feedback: 0/5 Correct. Accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "%run python/ir_system_part_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "__Note__: That the first time you run this, it will create a directory named `stemmed/` in `../data/RiderHaggard/.` This is meant to be a simple cache for the raw text documents. Later runs will be much faster after the first run. \n",
    "\n",
    "*However*, this means that if something happens during this first run and it does not get through processing all the documents, you may be left with an incomplete set of documents in `../data/RiderHaggard/stemmed/.` If this happens, simply remove the `stemmed/` directory and re-run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Part II\n",
    "---\n",
    "\n",
    "Continue improving the IR system by implementing:\n",
    "\n",
    "- __tf-idf:__ Compute and store the term-frequency inverse-document- frequency value for every word-document co-occurrence: $w_{t,d}=(1+\\text{log}_{10}\\text{tf}_{t,d})\\times\\text{log}_{10}(N/\\text{df}_t)$\n",
    "\n",
    "- **Cosine Similarity:** Implement cosine similarity in order to improve upon the ranked retrieval system, which currently retrieves documents based upon the Jaccard coefficient between the query and each document.\n",
    "\n",
    "__Also__ note that when computing $w_{t,q}$ (*i.e.* the weight for the word $w$ in the query) do *not* include the idf term. That is, $w_{t,q}=1+\\text{log}_{10}\\text{tf}_{t,q}$.\n",
    "\n",
    "To improve upon the information retrieval system, you must implement and/or improve upon the following functions:\n",
    "\n",
    "- `compute_tfidf():` This function computes and stores the tf-idf values for words and documents. For this you will probably want to be aware of the class variables `vocab` and `docs` which hold, respectively, the list of all unique words and the list of documents, where each document is a list of words.\n",
    "- `get_tfidf():` You must implement this function to return the tf-idf weight for a particular word and document ID.\n",
    "- `rank_retrieve():` This function returns a priority queue of the top ranked documents for a given query. Right now it ranks documents according to their Jaccard similarity with the query, but you will replace this method of ranking with a ranking using the cosine similarity between the documents and query.\n",
    "\n",
    "### Evaluation\n",
    "Your IR system will be evaluated on the same set of queries as Part I."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = (0.0, 0.0012129719579875974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012129719579875974"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = np.array([0.00035248849817672413, 0.000480736220837049, 0.013705969692277338, 0.0137251461712088, 0.0002797865799506651, 0.019910598775853015, 0.00039419905273530335, 0.004208302335074309, 0.013854648850356784, 0.026306592116295695, 0.011822643230757103, 0.015073732408683567, 0.0005263656250904375, 0.0004706373776212555, 0.003193260747224215, 0.00028424251440014236, 0.00777826474396481, 0.0005335521087039947, 0.000707321799318017, 0.01656664232207635, 0.014365057824115254, 0.03395182255044427, 0.01049646609235163, 0.012971272095269982, 0.0, 0.00043173711620603006, 0.0004114342133707079, 0.017709503939168703, 0.01583025492629836, 0.0006576365162332655, 0.0008930615116816803, 0.0010108409196868586, 0.0003819509186837837, 0.01582548203276347, 0.00055539361280049, 0.0007775714719955411, 0.001121614093162613, 0.0007846969716502821, 0.0003490563208753242, 0.0044937577385043715, 0.01582463652878535, 0.012288986022456424, 0.0003295915860527799, 0.005333484265173837, 0.017485728480475422, 0.001206626747581756, 0.0005512189358407156, 0.018081194364507433, 0.011260515224860148, 0.0007530916249290146, 0.0, 0.007808270960610167, 0.01928431579875561, 0.0008267645896079486, 0.0006266064258245398, 0.011397191062042017, 0.008214801185995517, 0.0007507636246918218, 0.00596395575871299,\\\n",
    "              0.0009051930534216257])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21,  9,  5, 52, 47, 27, 44, 19, 28, 33, 40, 11, 20,  8,  3,  2, 23,\n",
       "       41, 10, 55, 48, 22, 56, 51, 16, 58, 43, 39,  7, 14, 45, 36, 31, 59,\n",
       "       30, 53, 37, 35, 49, 57, 18, 29, 54, 34, 46, 17, 12,  1, 13, 25, 26,\n",
       "        6, 32,  0, 38, 42, 15,  4, 50, 24])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(l)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03395182,  0.02630659,  0.0199106 ,  0.01928432,  0.01808119,\n",
       "        0.0177095 ,  0.01748573,  0.01656664,  0.01583025,  0.01582548,\n",
       "        0.01582464,  0.01507373,  0.01436506,  0.01385465,  0.01372515,\n",
       "        0.01370597,  0.01297127,  0.01228899,  0.01182264,  0.01139719,\n",
       "        0.01126052,  0.01049647,  0.0082148 ,  0.00780827,  0.00777826,\n",
       "        0.00596396,  0.00533348,  0.00449376,  0.0042083 ,  0.00319326,\n",
       "        0.00120663,  0.00112161,  0.00101084,  0.00090519,  0.00089306,\n",
       "        0.00082676,  0.0007847 ,  0.00077757,  0.00075309,  0.00075076,\n",
       "        0.00070732,  0.00065764,  0.00062661,  0.00055539,  0.00055122,\n",
       "        0.00053355,  0.00052637,  0.00048074,  0.00047064,  0.00043174,\n",
       "        0.00041143,  0.0003942 ,  0.00038195,  0.00035249,  0.00034906,\n",
       "        0.00032959,  0.00028424,  0.00027979,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[np.argsort(l)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
=======
   "execution_count": 12,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in documents...\n",
      "Already stemmed!\n",
      "Indexing...\n",
      "[0, 7, 14, 25, 26, 34]  inv index\n",
      "Calculating tf-idf...\n",
      "===== Running tests =====\n",
      "Inverted Index Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
      "Boolean Retrieval Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
      "TF-IDF Test\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
      "Cosine Similarity Test\n",
      "Calculating Cosine Similarity....\n",
      "Calculating Cosine Similarity....\n",
      "Calculating Cosine Similarity....\n",
      "Calculating Cosine Similarity....\n",
      "Calculating Cosine Similarity....\n",
      "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "%run python/ir_system_part_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hints, Part I\n",
    "---\n",
    "\n",
    "> Smart data structures and dumb code works a lot better than the other way around.\n",
    "\n",
    "- Take your time - Read the instructions, skim the code, and __read the instructions again__. \n",
    "- `sets`, `Counters`, and `defaultdict` are your friends\n",
    "- indexes are your best friends\n",
    "- Build an instance of the system in in Jupyter Notebook or in `ipython`...."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 181,
=======
   "execution_count": 13,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in documents...\n",
      "Already stemmed!\n",
<<<<<<< HEAD
      "Indexing...\n",
      "[0, 7, 14, 25, 26, 34]  inv index\n",
      "Calculating tf-idf...\n",
      "Best matching documents to 'A tall tale about nothing':\n",
      "Calculating Cosine Similarity....\n",
      "Black Heart and White Heart: 1.420181e-03\n",
      "The Wizard: 1.169876e-03\n",
      "Queen of the Dawn (1925): 1.169574e-03\n",
      "The Ancient Allan: 1.155011e-03\n",
      "Moon of Israel: 1.143805e-03\n",
      "Maiwa's Revenge: 1.143378e-03\n",
      "Morning Star: 1.102587e-03\n",
      "Elissa: 1.078467e-03\n",
      "Swallow: a tale of the great trek: 1.066243e-03\n",
      "The Tale of Three Lions: 1.057001e-03\n"
=======
      "Indexing...\n"
>>>>>>> upstream/master
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\n",
    "%run python/ir_system_part_2.py \"A tall tale about nothing\""
=======
    "irsys = IRSystem()\n",
    "irsys.read_data('./data/RiderHaggard')\n",
    "irsys.index()\n",
    "\n",
    "print('Index built')"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array([1,0,0,0,0])"
=======
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enthusiast', 'hocuspocu', 'heavylik', 'relativeand', 'prayercarpet']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(irsys.vocab[:5])"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 152,
=======
   "execution_count": 16,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "1"
      ]
     },
     "execution_count": 152,
=======
       "['A Winter Pilgrimage (1901)',\n",
       " 'A Yellow God: an Idol of Africa',\n",
       " 'Allan Quatermain',\n",
       " 'Allan and the Holy Flower',\n",
       " 'Allan and the Ice Gods (1927)']"
      ]
     },
     "execution_count": 16,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "sum(p)"
=======
    "print(irsys.titles[:5])"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 180,
=======
   "execution_count": 24,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Reading in documents...\n",
      "Already stemmed!\n",
      "Indexing...\n",
      "[0, 7, 14, 25, 26, 34]  inv index\n",
      "Calculating tf-idf...\n",
      "Best matching documents to 'The space aliens were friendly':\n",
      "Calculating Cosine Similarity....\n",
      "The Virgin of the Sun: 1.449226e-02\n",
      "Wisdom's Daughter (1923): 1.339066e-02\n",
      "She and Allan: 1.286717e-02\n",
      "Queen of the Dawn (1925): 1.066689e-02\n",
      "Moon of Israel: 1.052042e-02\n",
      "Benita, an African romance: 9.707327e-03\n",
      "Allan Quatermain: 9.613126e-03\n",
      "Love Eternal: 9.341765e-03\n",
      "Stories by English Authors: Africa (Selected by Scribners): 9.311466e-03\n",
      "Heu-Heu (1924): 9.020179e-03\n"
=======
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(irsys.inv_index['withhold'])\n",
    "# print(irsys.inv_index['the'])\n",
    "# print(irsys.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Hints, Part II\n",
    "---\n",
    "\n",
    "- `np.log10` is __not__ the same as `np.log`\n",
    "- Test your system with custom queries:s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ir_system_part_2.py, line 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/brianspiering/github/DSCI6004-instructor/week_4/4_1_ir_I/exercise_information_retrieval/python/ir_system_part_2.py\"\u001b[0;36m, line \u001b[0;32m125\u001b[0m\n\u001b[0;31m    `\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run python/ir_system_part_2.py \"My very own query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ir_system_part_2.py, line 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/brianspiering/github/DSCI6004-instructor/week_4/4_1_ir_I/exercise_information_retrieval/python/ir_system_part_2.py\"\u001b[0;36m, line \u001b[0;32m125\u001b[0m\n\u001b[0;31m    `\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
>>>>>>> upstream/master
     ]
    }
   ],
   "source": [
    "%run python/ir_system_part_2.py \"The space aliens were friendly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ir_system_part_2.py, line 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/brianspiering/github/DSCI6004-instructor/week_4/4_1_ir_I/exercise_information_retrieval/python/ir_system_part_2.py\"\u001b[0;36m, line \u001b[0;32m125\u001b[0m\n\u001b[0;31m    `\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run python/ir_system_part_2.py \"The space aliens were friendly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [nlp]",
   "language": "python",
   "name": "Python [nlp]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
