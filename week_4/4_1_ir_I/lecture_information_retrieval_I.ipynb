{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Information Retrieval (IR)\n",
    "----\n",
    "\n",
    "![](http://boston.lti.cs.cmu.edu/classes/11-744/treclogo-c.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://2.bp.blogspot.com/-cH7ahEOwClg/US7fo0mbloI/AAAAAAAAAlU/nCYCyfS5ztI/s1600/intelligize-logo-534x226.png)\n",
    "\n",
    "[Intelligize](http://www.intelligize.com/) \n",
    "\n",
    "> Efficiently search, retrieve and analyze SEC filings, agreements and exhibits. Utilize advanced analytics and comparison tools to pinpoint only the most relevant precedents.\n",
    "\n",
    "> Access statutes, rules, regulations and other materials pertinent to US capital markets.   \n",
    "> Granularly search through Comment Letters, corresponding responses, and No-Action Letters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Explain what is IR and why it is important\n",
    "- Draw an IR system\n",
    "- Evaluate an IR system with the following concepts:  \n",
    "    - Precision and recall\n",
    "    - Precision at k\n",
    "    - Mean average precision\n",
    "- Create a basic IR system with the following features:\n",
    "    - Document-term matrix\n",
    "    - Boolean retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Information Retrieval (IR)\n",
    "----\n",
    "\n",
    "IR is just one small nested part of \"search engines\", there are large product and computer science parts.\n",
    "\n",
    "We are going to focus on the NLP, Statistics, and Machine Learning aspects.  \n",
    "(However, I will give you some general tips to impress people.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/search_engine.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "IR System: The NLP parts\n",
    "---\n",
    "\n",
    "![](http://www.mactech.com/content_images/macsimum/uploads/MultiLanguagePatent.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Information Retrieval Process (Fundamental)\n",
    "-----\n",
    "\n",
    "1. Given a collection of documents \n",
    "1. And an userâ€™s query\n",
    "1. Find the most relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key IR Terms\n",
    "----\n",
    "\n",
    "- Query\n",
    "- Document\n",
    "- Collection\n",
    "- Index\n",
    "- Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Query\n",
    "----\n",
    "\n",
    "A representation of what the user is looking for. \n",
    "\n",
    "Can be stored as a tuple of ngrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Document\n",
    "----\n",
    "\n",
    "An information entity that the user wants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Not just a \"paper\" item\n",
    "- Can be records (medical), pages (websites), images, people, or movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Document Storage\n",
    "-------\n",
    "\n",
    "1. Actual item representation (for users)\n",
    "1. Value-added representation (for the system)\n",
    "    - metadata\n",
    "    - fixed unicode\n",
    "    - tokens and counts\n",
    "    - links to it (PageRank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Collection\n",
    "----\n",
    "\n",
    "A set of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Index\n",
    "-----\n",
    "\n",
    "A representation of information that makes querying easier\n",
    "\n",
    "What would be a good Python data structure for an index?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "{'hoe': {0, 1, 9, 12},\n",
    "'rake': {0, 1, 5, 9}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Term\n",
    "----\n",
    "\n",
    "Word, token, or ngrams that appears in a document or a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Document Representations\n",
    "-----\n",
    "\n",
    "Term-document matrix (m x n)\n",
    "\n",
    "Document-document matrix (n x n)\n",
    "\n",
    "Remember Heaps' Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluation Metrics\n",
    "----\n",
    "\n",
    "- Precision and recall\n",
    "- Precision at k\n",
    "- Mean average precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Confusion Matrix\n",
    "----\n",
    "\n",
    "![](images/cont.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/p_tp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/recall_tp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/items.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/recall.png)\n",
    "<img src=\"images/items.png\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/precision.png)\n",
    "<img src=\"images/items.png\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/r.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/p.png)\n",
    "![](images/r.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/pvsr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "If there are 100 documents in a collection that are relevant to a given query and 60 of these items are retrieved in a given search. \n",
    "\n",
    "What is the recall?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Recall = (60/100) = .60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a given search, the system retrieves 80 items, out of which 30 are relevant and 50 are non-relevant. \n",
    "\n",
    "What is the precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Precison = (30/80) = .375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/trump.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "When a query have thousands (or millions) of relevant documents, recall is often not a meaningful metric.\n",
    "\n",
    "No one interested in reading all of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Search Engine Results Page (SERP)\n",
    "-----\n",
    "\n",
    "1st position is most important\n",
    "\n",
    "2nd position is sometimes clicked on\n",
    "\n",
    "3rd position is rarely clicked on\n",
    "\n",
    "4th-end Doesn't matter\n",
    "\n",
    "----\n",
    "\n",
    "Above the fold is all that matters. The fold (aka attention) is getting smaller. For example, compare desktop to mobile to watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Need \"precision at k\" or p@k\n",
    "----\n",
    "\n",
    "[P@10 or \"Precision at 10\"](https://en.wikipedia.org/wiki/Mean_average_precision#Precision_at_K) corresponds to the number of relevant results on the first search results page which typically has 10 shown results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is precision at different k for this SERP?\n",
    "\n",
    "1. N / not relevant document\n",
    "2. N / not relevant document\n",
    "3. N / not relevant document\n",
    "4. R / relevant document\n",
    "5. R / relevant document\n",
    "6. N / not relevant document\n",
    "7. R / relevant document \n",
    "8. R / relevant document \n",
    "9. N / not relevant document\n",
    "10. R / relevant document\n",
    "11. R / relevant document\n",
    "12. N / not relevant document\n",
    "13. R / relevant document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Here is our data\n",
    "serp = 'N N N R R N R R N R R N R'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to boolean vector\n",
    "serp_relevant = [relevance == 'R' # R = relevant \n",
    "                 for relevance in serp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serp_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Caluclate precision at each k\n",
    "precisions = [sum(serp_relevant[:k+1])/(k+1) \n",
    "               for k, relevant in enumerate(serp_relevant) \n",
    "               if relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at relevant item: \n",
      "0.25\n",
      "0.4\n",
      "0.42857142857142855\n",
      "0.5\n",
      "0.5\n",
      "0.5454545454545454\n",
      "0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "# What are the precisions?\n",
    "print(\"Precision at relevant item: \")\n",
    "print(*precisions, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision for this query: 0.45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Average precision for this query: {:.2f}\".format(np.mean(precisions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "System performance across multiple queries\n",
    "\n",
    "![](images/map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "-----\n",
    "\n",
    "- All significantly advanced tech companies will make their own IR system\n",
    "- IR Systems:\n",
    "    - Have a collection of documents\n",
    "    - Process an user's query\n",
    "    - Returns a SERP\n",
    "- Evaluate a SERP with:\n",
    "    + Precision \n",
    "    + Recall\n",
    "    + p@k\n",
    "    + MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Advanced metrics\n",
    "----\n",
    "\n",
    "[Fall-out](https://en.wikipedia.org/wiki/Information_retrieval#Fall-out): The proportion of non-relevant documents that are retrieved, out of all non-relevant documents available. \n",
    "\n",
    "![](images/fallout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "[Generality](http://crpit.com/confpapers/CRPITV49Yan.pdf): The proportion of relevant items per query.\n",
    "    \n",
    "Larger the collection, the larger will be the number of non-relevant item in given query. Hence, an increase in the level of recall will cause a decrease in precision.\n",
    "\n",
    "[Source](http://www.cs.usc.edu/assets/002/82932.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
