{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "Information Retrieval\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Describe the need to order SERP\n",
    "- Use Jaccard similarity to quantify the relationship between a query and document\n",
    "- Use Cosine similarity to measure the distance between query and document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Distance Metrics\n",
    "-----\n",
    "\n",
    "> \"It's like being in a library where someone has scattered all the books on the floor, attached them together with threads and you are in the dark.\"  \n",
    "> /- MorningSide, CBC Radio, May 1995\n",
    "\n",
    "The need for ranking SERP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Jaccard similarity\n",
    "----\n",
    "\n",
    "![](images/jaccard.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://dataaspirant.files.wordpress.com/2015/04/jaccard_similariyt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "![](https://dataaspirant.files.wordpress.com/2015/04/jaccaard2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://dataaspirant.files.wordpress.com/2015/04/jaccaard3.png)\n",
    "\n",
    "[Source](https://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why Jaccard similarity?\n",
    "----\n",
    "\n",
    "Apply set operations to get distance between items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is a simple recommender system! Your content could be words, images, or wines.\n",
    "\n",
    "__Hint__: Do this first, way before collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you calculate Jaccard similarity?\n",
    "---\n",
    "<img src=\"images/trumpy.jpg\" style=\"width: 300px;\"/>\n",
    "<img src=\"images/collins.png\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "q1 = \"I mean, part of the beauty of me is that I'm very very rich.\"\n",
    "q2 = \"The problem with beauty is that it's like being born rich and getting poorer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/jaccard.png)\n",
    "\n",
    "jaccard_sim(q1, q2) = 5/21 = 0.238"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Student Activity\n",
    "\n",
    "Write a function to calculate Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "def jaccard_sim(a, b):\n",
    "    \"\"\"Calculate the jaccard similarity of the 2 docuents.\n",
    "    jaccard similarity is the overlap of two sets.\n",
    "    jaccard_sim = |A intersection B| / | A union B|\n",
    "    \"\"\"\n",
    "    # Munging\n",
    "    a = a.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "    b = b.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"'\", \"\")\n",
    "\n",
    "    a = set(a.split())\n",
    "    b = set(b.split())\n",
    "    \n",
    "    return Fraction(len(a.intersection(b)), len(a.union(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraction(5, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_sim(q1, q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are limitations of Jaccard similarity?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Assumes items are hashable (aka, able to make into members of a set).  \n",
    "\n",
    "2. Ignores rate, how often a item appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the cosine similarity?\n",
    "---\n",
    "\n",
    "![](https://dataaspirant.files.wordpress.com/2015/04/cosine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/cosine_similarity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why is cosine similarity so powerful?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. It is a vector based distance metric thus is fast and easy to calculate.  \n",
    "\n",
    "2. It easy to interpret because it is bounded between -1 and 1.\n",
    "\n",
    "[Cosine similarity calculator](http://www.appliedsoftwaredesign.com/archives/cosine-similarity-calculator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "tf-idf\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is tf-idf?\n",
    "----\n",
    "\n",
    "term frequencyâ€“inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Why tf-idf?\n",
    "---\n",
    "\n",
    "A __single__ statistical measure used to evaluate how important a word is to a document in a collection. \n",
    "\n",
    "The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the tf-idf formula?\n",
    "-----\n",
    "\n",
    "![](https://deeplearning4j.org/img/tfidf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://deeplearning4j.org/img/tfidf.png)\n",
    "\n",
    "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "IDF(t) = log(Total number of documents / Number of documents with term t in it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Wieghted by log scale (not linearily), if a term 100x common is not 100x more relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://3.bp.blogspot.com/-jAaRras-pOM/UXNQOMnz1BI/AAAAAAAAnYA/9FwvHPOp90c/s1600/TFIDF-FIG-01.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "How to build a IR system\n",
    "----\n",
    "\n",
    "1. Convert the document to tf-idf vector\n",
    "1. Convert the query to tf-idf vector\n",
    "1. Compute cosine similarity between document vector and query vector\n",
    "1. Rank documents\n",
    "1. Return top K scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Putting tf-idf and cosine similarity together\n",
    "----\n",
    "![](http://images.slideplayer.com/8/2321076/slides/slide_7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://nlp.stanford.edu/IR-book/html/htmledition/img411.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "---\n",
    "\n",
    "Queries are short and documuents are long. How does the system handle that?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The vectors are normalized to account variety of lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "----\n",
    "\n",
    "- We need to rank our SERP to increase precision@k\n",
    "- We can do that by finding the similarity between the query and the documents\n",
    "- Cosine similarity is a good distance metric\n",
    "- tf-idf vectorizes the query and document to then calculate the distance metric\n",
    "- Jaccard similarity is also an okay distance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
