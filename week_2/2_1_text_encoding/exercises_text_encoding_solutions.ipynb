{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://db.tt/S4xIuOL4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeError",
     "evalue": "Hey wait, this isn't Unicode.\n\nftfy is designed to fix problems that were introduced by handling Unicode\nincorrectly. It might be able to fix the bytes you just handed it, but the\nfact that you just gave a pile of bytes to a function that fixes text means\nthat your code is *also* handling Unicode incorrectly.\n\nftfy takes Unicode text as input. You should take these bytes and decode\nthem from the encoding you think they are in. If you're not sure what encoding\nthey're in:\n\n- First, try to find out. 'utf-8' is a good assumption.\n- If the encoding is simply unknowable, try running your bytes through\n  ftfy.guess_bytes. As the name implies, this may not always be accurate.\n\nIf you're confused by this, please read the Python Unicode HOWTO:\n\n    http://docs.python.org/3/howto/unicode.html\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-87e44573266b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mftfy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/brianspiering/anaconda/envs/nlp/lib/python3.5/site-packages/ftfy/__init__.py\u001b[0m in \u001b[0;36mfix_text\u001b[0;34m(text, fix_entities, remove_terminal_escapes, fix_encoding, fix_latin_ligatures, fix_character_width, uncurl_quotes, fix_line_breaks, fix_surrogates, remove_control_chars, remove_bom, normalization, max_decode_length)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mUnicodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES_ERROR_TEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeError\u001b[0m: Hey wait, this isn't Unicode.\n\nftfy is designed to fix problems that were introduced by handling Unicode\nincorrectly. It might be able to fix the bytes you just handed it, but the\nfact that you just gave a pile of bytes to a function that fixes text means\nthat your code is *also* handling Unicode incorrectly.\n\nftfy takes Unicode text as input. You should take these bytes and decode\nthem from the encoding you think they are in. If you're not sure what encoding\nthey're in:\n\n- First, try to find out. 'utf-8' is a good assumption.\n- If the encoding is simply unknowable, try running your bytes through\n  ftfy.guess_bytes. As the name implies, this may not always be accurate.\n\nIf you're confused by this, please read the Python Unicode HOWTO:\n\n    http://docs.python.org/3/howto/unicode.html\n"
     ]
    }
   ],
   "source": [
    "ftfy.fix_text(b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'にな 珦饦フォ 䩨ぽ珦饦フォ 窯りゅウ穟\\tて わガ觜フェ嫧, げ拥 䥜駺コグァ谯 餚嶣卤ゞ蟤 ゐイを, フォ氩 イを焨䤤ミ きょきゅ覵ら䤎 にゃ盨穃ぢゃぶ 騌䪦代 砥ツォ イを焨䤤ミ 䋨襊僯にゅじょ 餚嶣卤ゞ蟤 苯楥り 狨キュ坣 び愦にな秚 尦解㛥祧靨 樚駌娦禞簯 そ窯, 簥㣌のづ䨣 ぜウァ狨キュ坣 こ查ッ襪褚 裪蝥 䋨襊僯, 䧪きぎゃ りれ짦ちょ樊 㠣ぢょ䧨どヴェ 襪褚 きゃぐ 極背媥 黨ぢゅ馨䧞ご 择ほぎゅ櫦みゅ, 珦饦フォ わガ觜フェ嫧 んぴょじゅ磊お きょきゅ覵ら䤎 勤睥 窯りゅウ穟\\tて げ拥けドひ リョ榯㠨 榞妦, ぜウァ狨キュ坣 ケ覟橣榧ゐ み鏨ぴ栧䤥 滩矩 じ䧺榊\\r\\rいジャぎ 杯まぞ䤂禯 馺シェ觩ざ䪥 んぴょじゅ磊お のづ, べぜウァ 䥜駺コグァ谯 棃じゃ䥺みょ果 馣ぱゔ榞妦 媥さ 簥㣌のづ䨣 黧いジャぎじ 裪蝥 褚礥へ, 姥そ窯 棃じゃ䥺みょ果 ㄦタ馦䦞ぼ りょく 㠨もし䏦べ 竤ホ*ン杦誣 秤詃 諧う秤, 䨵饣す馜窣 餚嶣卤ゞ蟤 查ッ襪 秚ふ 䧪きぎゃ苯楥 イを焨䤤ミ 䧺榊諧う秤 苯楥り シェ觩 る䏨 極背媥 きょきゅ覵ら䤎 ㄦタ馦䦞ぼ, 䝣狧 樊リュる 㠣ぢょ䧨どヴェ 礥へやぴゅびゃ, 㠣ぢょ䧨どヴェ にゃ盨穃ぢゃぶ イを 諧う秤 䧪きぎゃ 䩨ぽ珦饦フォ わガ觜フェ嫧 媥さ\\r\\r褚礥へ ひ尦 㠨もし䏦べ み鏨ぴ栧䤥 择ほぎゅ櫦みゅ ㄦタ馦䦞ぼ 䦤にょ奟 みゅ䣥, スィ䦤にょ奟グェ 馺シェ觩ざ䪥 䧺榊諧う秤 諧う秤 んぴょ ぜウァ狨キュ坣 嫯ヲ奎裪蝥 餚嶣卤ゞ蟤 イを 磊おぎょ, 姌饜竨ね姎 餚嶣卤ゞ蟤 滩矩 饜竨ね みゅ䣥𐤦 䨵饣す馜窣 きょきゅ覵ら䤎 簯み, ぎじ 黨ぢゅ馨 リュる䏨た餣 㠣ぢょ䧨どヴェ, 鰧䝣狧樃壃 馺シェ觩ざ䪥 グェ䨵饣 焯ろ 涯砥ツォ 焨䤤 スィ䦤にょ奟グェ わガ觜フェ嫧\\r\\rじゅ磊 リュる䏨た餣 嫯ヲ奎裪蝥 䋨襊僯にゅじょ 詃ヌ婩, ざ䪥 卤ゞ蟤 㠨もし䏦べ 餚嶣卤ゞ蟤 䦞ぼ び愦にな秚 䩨ぽ珦饦フォ 棃じゃ䥺みょ果 馯饎スィ, リュる䏨た餣 䨵饣す馜窣 觜フェ嫧 馯饎 び愦にな秚 窨しょ滩矩睢 諧う秤 にな, げ拥けドひ 黧いジャぎじ フェ嫧 㛥祧靨 窯りゅウ穟\\tて ル稧焯ろ䩎 ゝ㫤しゅ た餣, 䥺みょ ル稧焯ろ䩎 ヘ㛤饧りゃ駪 いジャぎ, 䩨ぽ珦饦フォ こ查ッ襪褚 え稪 ゝ㫤しゅ\\r\\r簥㣌のづ䨣 狥㠯む姥そ 竤ホ*ン杦誣 諧う秤 卤ゞ いジャぎ る䏨 㠣ぢょ䧨どヴェ 棃じゃ䥺みょ果, イを焨䤤ミ 餚嶣卤ゞ蟤 卤ゞ \\tて杯ま ぜウァ狨キュ坣 嫯ヲ奎裪蝥 餚嶣卤ゞ蟤 *ン杦 グェ䨵饣, 䥜駺コグァ谯 尦解㛥祧靨 择ほぎゅ櫦みゅ 䏨た餣 ミ嫯 䧨ど 騌䪦代 ル稧焯ろ䩎 馣ぱゔ榞妦\\r\\rりょくがひゃビェ ぎょ極背媥さ んぴょ ル稧焯, ヘ㛤 きょきゅ覵ら䤎 黨ぢゅ馨䧞ご \\tて杯ま え稪 卤ゞ蟤 䥜駺コグァ谯 杯まぞ䤂禯 餚嶣卤ゞ蟤 嫯ヲ奎裪蝥 ヘ㛤饧りゃ駪 ゐイを と馩, 姎餚嶣 リュる䏨た餣 りょくがひゃビェ わガ觜フェ嫧 襪褚 ぢゃぶ黧 栧䤥 げ拥けドひ 尦解㛥祧靨, イを焨䤤ミ 䋨襊僯にゅじょ ぱゔ \\tて杯ま, にゅじょ 䧪きぎゃ リュる䏨た餣 簥㣌のづ䨣 わガ觜フェ嫧 ヴョ䋧と馩ぬ 䣥𐤦涯砥ツォ りれ にゃ盨穃, 秚ふ 氩めぺ んぴょじゅ磊お 黨ぢゅ馨䧞ご み鏨ぴ栧䤥 極背媥 リュる䏨た餣 㠨もし䏦べ ヲ奎, ふえ稪廦メ こ查ッ襪褚 苯楥り 饜竨, 姌饜竨ね姎 择ほぎゅ櫦みゅ にゃ盨穃ぢゃぶ にゅじょ ぢゃぶ黧 樊リュ ひゃビェケ 䧪きぎゃ苯楥 み鏨ぴ栧䤥, 嫯ヲ奎裪蝥 こ查ッ襪褚 樚駌娦禞簯 ひ尦解 䨣䥜\\r\\r嫯ヲ奎 ふえ稪廦メ ゝ㫤しゅきゃぐ 榧ゐ, わガ觜フェ嫧 馺シェ觩ざ䪥 果馺 づ䨣䥜, にゃ盨穃 樚駌娦禞簯 䧺榊諧う秤 䦞ぼ 勤睥つ㨣ちゃ 簥㣌のづ䨣 ぢゃぶ黧 シェ觩, 氩めぺ 樚駌娦禞簯 䧺榊諧う秤 䧨ど, 䧨ど ぎょ極背媥さ み鏨ぴ栧䤥 嫯ヲ奎 グァ谯 䥜駺コグァ谯 ぎょ極背媥さ ヘ㛤饧りゃ駪 果馺シェ, 氩めぺ馯饎 ル稧焯ろ䩎 尦解㛥祧靨 苯楥り し䏦, 樚駌娦禞簯 ゝ㫤しゅきゃぐ 黧いジャぎじ ほぎゅ櫦 馜窣 娦禞 狥㠯む姥そ 嫯ヲ奎裪蝥 䧺榊諧う秤 れ짦ちょ 極背媥 杯まぞ䤂禯 鰧䝣狧樃壃 栧䤥, 簥㣌のづ䨣 餚嶣卤ゞ蟤 鰧䝣狧樃壃 ホ*ン杦 りゅウ ゐイを 氩めぺ馯饎 み鏨ぴ栧䤥 ビェケ, 涯砥ツォ 择ほぎゅ櫦みゅ 䣥𐤦涯砥ツォ 㫤しゅ\\r\\r鰧䝣狧樃壃 きょきゅ覵ら䤎 查ッ な秚ふ, む姥 禞簯み 狥㠯む姥そ 詃ヌ婩韥槥 ヲ奎 ケ覟橣榧ゐ イを焨䤤ミ 樊リュる, 鰧䝣狧 勤睥つ㨣ちゃ 䧪きぎゃ苯楥 黧いジャぎじ 廦メ 㠨も 勤睥つ㨣ちゃ 㠨もし䏦べ 餚嶣卤ゞ蟤 もし䏦 ぬ馣 わガ觜フェ嫧 黨ぢゅ馨䧞ご りゅウ穟, リュる䏨た餣 姌饜竨ね姎 䣥𐤦涯砥ツォ りゅウ穟 タ馦 る䏨 みゅ䣥𐤦 りれ짦ちょ樊 ぎょ極背媥さ 䣥𐤦涯砥ツォ, めぺ 窨しょ滩 ふえ稪廦メ 棃じゃ䥺みょ果 み鏨ぴ栧䤥, び愦にな秚 狥㠯む姥そ 查ッ す馜窣\\r\\rさきょきゅ 䦞ぼ 簥㣌のづ䨣 尦解㛥祧靨 馦䦞ぼ ミ嫯 騌䪦代リョ榯 こ查ッ襪褚 䣥𐤦涯砥ツォ ゝ㫤しゅきゃぐ 詃ヌ婩韥槥 べぜ じ䧺榊, 㠨もし䏦べ 择ほぎゅ櫦みゅ 黧いジャぎじ 卤ゞ蟤 にな じ䧺榊 䧪きぎゃ苯楥 リュる䏨た餣 䨵饣す馜窣 ヴェわ, リュる䏨た餣 イを焨䤤ミ 馺シェ觩ざ䪥 ゔ榞妦 ぞ䤂 騌䪦代リョ榯 りょくがひゃビェ 樃壃棃 樃壃 詃ヌ婩 騌䪦代リョ榯 きょきゅ覵ら䤎 ひ尦, 饜竨ね ビェケ 窯りゅウ穟\\tて 择ほぎゅ櫦みゅ\\r\\rきょきゅ づ䨣䥜 び愦にな秚 䋨襊僯にゅじょ 姌饜竨ね姎 餚嶣卤ゞ蟤 み鏨ぴ栧䤥 び愦 詃ヌ婩, 䧺榊 ケ覟橣榧ゐ 䋨襊僯にゅじょ きゃぐ择, る䏨 䥜駺コグァ谯 樚駌娦禞簯 ㄦタ馦䦞ぼ 詃ヌ婩 簯み りゅウ穟 ぜウァ狨キュ坣 䣥𐤦涯砥ツォ 黧いジャぎじ, び愦 ふえ稪廦メ ヘ㛤饧りゃ駪 りゅウ穟 㠣ぢょ䧨どヴェ 䣥𐤦涯砥ツォ 棃じゃ 卤ゞ蟤 りゅウ穟 裪蝥 簥㣌のづ䨣 樚駌娦禞簯, べぜ 䨵饣す馜窣 黨ぢゅ馨䧞ご \\tて杯ま れ짦ちょ ル稧焯ろ䩎 んぴょじゅ磊お にゃ盨穃ぢゃぶ *ン杦 誣ㄦ 䥜駺コグァ谯 㠣ぢょ䧨どヴェ 䣥𐤦涯砥ツォ きゃぐ择, 涯砥ツォ 䩨ぽ珦饦フォ 黧いジャぎじ 饣す\\r      '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "2)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../../corpora/emoji_table.txt') as f:\n",
    "    emojis = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['👪,E_family',\n",
       " '👨\\u200d👩\\u200d👧,E_family1',\n",
       " '👨\\u200d👩\\u200d👧\\u200d👦,E_family2',\n",
       " '👨\\u200d👩\\u200d👦\\u200d👦,E_family3',\n",
       " '👨\\u200d👩\\u200d👧\\u200d👧,E_family4',\n",
       " '👩\\u200d👩\\u200d👦,E_family5',\n",
       " '👩\\u200d👩\\u200d👧,E_family6']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis[318:325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'👨\\u200d👩\\u200d👧\\u200d👦,E_family2'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji = emojis[320]\n",
    "emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+1F468  👨       [So] MAN\n",
      "U+200D  \\u200d  [Cf] ZERO WIDTH JOINER\n",
      "U+1F469  👩       [So] WOMAN\n",
      "U+200D  \\u200d  [Cf] ZERO WIDTH JOINER\n",
      "U+1F467  👧       [So] GIRL\n",
      "U+200D  \\u200d  [Cf] ZERO WIDTH JOINER\n",
      "U+1F466  👦       [So] BOY\n",
      "U+002C  ,       [Po] COMMA\n",
      "U+0045  E       [Lu] LATIN CAPITAL LETTER E\n",
      "U+005F  _       [Pc] LOW LINE\n",
      "U+0066  f       [Ll] LATIN SMALL LETTER F\n",
      "U+0061  a       [Ll] LATIN SMALL LETTER A\n",
      "U+006D  m       [Ll] LATIN SMALL LETTER M\n",
      "U+0069  i       [Ll] LATIN SMALL LETTER I\n",
      "U+006C  l       [Ll] LATIN SMALL LETTER L\n",
      "U+0079  y       [Ll] LATIN SMALL LETTER Y\n",
      "U+0032  2       [Nd] DIGIT TWO\n"
     ]
    }
   ],
   "source": [
    "ftfy.explain_unicode(emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more:\n",
    "- http://www.fileformat.info/info/unicode/char/200d/index.htm\n",
    "- http://archives.miloush.net/michkap/archive/2006/02/15/532394.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mungle the text\n",
    "emojis = [emoji.replace('\\u200d', '') for emoji in emojis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'👨👩👧👦,E_family2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji = emojis[320]\n",
    "emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['emoji', 'meaning'],\n",
       " ['😄', 'A_smiley1'],\n",
       " ['😃', 'A_smiley2'],\n",
       " ['😀', 'A_smiley3'],\n",
       " ['😊', 'A_smiley4']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_label_splits = (emoji.split(\",\") for emoji in emojis)\n",
    "list(emoji_label_splits)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emoji_label_splits = (emoji.split(\",\") for emoji in emojis)\n",
    "emoji_map = {label.lower(): emoji for emoji,label in emoji_label_splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1e3428b00ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0memoji_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e_family2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'👨👩👧👦'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0memoji_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_ok'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'👌'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0memoji_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd_poop'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'💩'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert emoji_map['e_family2'] == '👨👩👧👦'\n",
    "assert emoji_map['d_ok'] == '👌'\n",
    "assert emoji_map['d_poop'] == '💩'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
