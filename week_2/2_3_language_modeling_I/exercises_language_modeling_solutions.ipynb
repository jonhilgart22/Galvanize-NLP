{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write a function to sample an *n* word sentence from a bag of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../../../corpora/the_kama_sutra.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def words(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'he', 'page', 'whose', 'a']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karma = words(text)\n",
    "karma[:5]\n",
    "\n",
    "import random \n",
    "\n",
    "random.shuffle(karma)\n",
    "bag = karma\n",
    "bag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def sample(bag, n=10):\n",
    "    \"Sample a random n-word sentence from the model described by the bag of words.\"\n",
    "    return ' '.join(random.choice(bag) for _ in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and expressing but should love tell are arise any and',\n",
       " 'the esprit her no the the of condoling with to',\n",
       " 'wife to respect for husband only kinds the the her',\n",
       " 'of the many he be good same once of tenth',\n",
       " 'should the out women at her the festival show young',\n",
       " 'return who now gained inarticulately infant marks is get attending',\n",
       " 'known or lip and distress the his moreover weary common',\n",
       " 'of has a these and her amusements by bite expressive',\n",
       " 'about salt who the wife he superintend secrets men union',\n",
       " 'may with her time diversions plain ministers the draupadi excessive']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sample(bag) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of ngram model is this? Why?\n",
    "\n",
    "1. unigram\n",
    "2. bigram\n",
    "3. trigram\n",
    "4. none of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is unigram model. It generative data based on single token frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4487),\n",
      " ('of', 2957),\n",
      " ('and', 2224),\n",
      " ('to', 1560),\n",
      " ('a', 1478),\n",
      " ('her', 1081),\n",
      " ('is', 999),\n",
      " ('in', 980),\n",
      " ('should', 812),\n",
      " ('with', 717)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "counts = Counter(karma)\n",
    "pprint(counts.most_common(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  count\n",
      "there                 120\n",
      "are                   425\n",
      "common                11\n",
      "and                   2224\n",
      "neverseen             0\n",
      "words                 41\n"
     ]
    }
   ],
   "source": [
    "print('{0:20}  {1}'.format(\"word\", \"count\"))\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print('{0:20}  {1}'.format(word, counts[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there                 0.002\n",
      "are                   0.0072\n",
      "common                0.00019\n",
      "and                   0.038\n",
      "neverseen             0.0\n",
      "words                 0.0007\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate the frequency of the words\n",
    "\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print('{0:20}  {1:.2}'.format(word, counts[word]/sum(counts.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Turn that into a function\n",
    "def calc_prob_distibution(counter):\n",
    "    \"Calculate a probability distribution based on evidence from a Counter.\"\n",
    "    N = sum(counter.values())\n",
    "    return lambda x: counter[x]/N\n",
    "\n",
    "prob_distrubtion = calc_prob_distibution(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert round(prob_distrubtion(\"the\"), 4) == 0.0764\n",
    "assert round(prob_distrubtion(\"with\"), 4) == 0.0122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  frequency\n",
      "there                 0.002\n",
      "are                   0.0072\n",
      "common                0.00019\n",
      "and                   0.038\n",
      "neverseen             0.0\n",
      "words                 0.0007\n"
     ]
    }
   ],
   "source": [
    "print('{0:20}  {1}'.format(\"word\", \"frequency\"))\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print('{0:20}  {1:.2}'.format(word, prob_distrubtion(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is the probability of a *sequence* of words?  Use the definition of a joint probability:\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_1 w_2) \\ldots  \\times \\ldots P(w_n \\mid w_1 \\ldots w_{n-1})$\n",
    "\n",
    "The *bag of words* model assumes that each word is drawn from the bag *independently* of the others.  This gives us the wrong approximation:\n",
    "    \n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2) \\times P(w_3) \\ldots  \\times \\ldots P(w_n)$\n",
    "\n",
    "It is wrong but okay enough to move forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def product(iterable):\n",
    "    \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "def prob_words(words):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product(prob_distrubtion(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the the                     0.000445474\n",
      "the son                         7.79968e-06\n",
      "the son of a Brahman            3.02572e-12\n",
      "this is a neverbeforeseen word  0.0\n"
     ]
    }
   ],
   "source": [
    "phrases = ['the the the',\n",
    "         'the son',\n",
    "         'the son of a Brahman', \n",
    "         'this is a neverbeforeseen word']\n",
    "\n",
    "for phrase in phrases:\n",
    "    print('{0:30}  {1:.6}'.format(phrase, prob_words(words(phrase))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why is `the the the` so likely? What would we have to add to our model to reduce the likelihood of nonsense phrases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bigrams or grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO: Why is there zero probability for sentence with neverbeforseen word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Let's move up from millions to *billions and billions* of words.  \n",
    "\n",
    "Once we have that amount of data, we can start to look at two word sequences, without them being too sparse.  \n",
    "\n",
    "We happen to have data files available in the format of `\"word \\t count\"`, and bigram data in the form of `\"word1 word2 \\t count\"`.  Let's arrange to read them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_counts(filename, sep='\\t'):\n",
    "    \"\"\"Return a Counter initialized from key-value pairs, \n",
    "    one on each line of filename.\"\"\"\n",
    "    C = Counter()\n",
    "    for line in open(filename):\n",
    "        key, count = line.split(sep)\n",
    "        C[key] = int(count)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333,333\n",
      "286,358\n"
     ]
    }
   ],
   "source": [
    "counts_unigram = load_counts('../../../corpora/unigram_word_counts.txt')\n",
    "counts_bigram = load_counts('../../../corpora/bigram_word_counts.txt')\n",
    "\n",
    "print(\"{:,}\".format(len(counts_unigram)))\n",
    "print(\"{:,}\".format(len(counts_bigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588,124,220,187\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\".format(sum(counts_unigram.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225,955,251,755\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\".format(sum(counts_bigram.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23135851162),\n",
       " ('of', 13151942776),\n",
       " ('and', 12997637966),\n",
       " ('to', 12136980858),\n",
       " ('a', 9081174698),\n",
       " ('in', 8469404971),\n",
       " ('for', 5933321709),\n",
       " ('is', 4705743816),\n",
       " ('on', 3750423199),\n",
       " ('that', 3400031103),\n",
       " ('by', 3350048871),\n",
       " ('this', 3228469771),\n",
       " ('with', 3183110675),\n",
       " ('i', 3086225277),\n",
       " ('you', 2996181025)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_unigram.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the', 2766332391),\n",
       " ('in the', 1628795324),\n",
       " ('to the', 1139248999),\n",
       " ('on the', 800328815),\n",
       " ('for the', 692874802),\n",
       " ('and the', 629726893),\n",
       " ('to be', 505148997),\n",
       " ('is a', 476718990),\n",
       " ('with the', 461331348),\n",
       " ('from the', 428303219),\n",
       " ('by the', 417106045),\n",
       " ('at the', 416201497),\n",
       " ('of a', 387060526),\n",
       " ('in a', 364730082),\n",
       " ('will be', 356175009),\n",
       " ('that the', 333393891),\n",
       " ('do not', 326267941),\n",
       " ('is the', 306482559),\n",
       " ('to a', 279146624),\n",
       " ('is not', 276753375),\n",
       " ('for a', 274112498),\n",
       " ('with a', 271525283),\n",
       " ('as a', 270401798),\n",
       " ('<S> and', 261891475),\n",
       " ('of this', 258707741),\n",
       " ('<S> the', 258483382),\n",
       " ('it is', 245002494),\n",
       " ('can be', 230215143),\n",
       " ('If you', 210252670),\n",
       " ('has been', 196769958),\n",
       " ('the same', 186235801),\n",
       " ('does not', 180844574),\n",
       " ('can not', 180466484),\n",
       " ('and a', 178504444),\n",
       " ('in this', 174166565),\n",
       " ('one of', 173898508),\n",
       " ('have been', 172884791),\n",
       " ('you can', 172007760),\n",
       " ('may be', 171738006),\n",
       " ('as the', 169662690),\n",
       " ('on a', 167105962),\n",
       " ('the first', 159289000),\n",
       " ('have a', 156027480),\n",
       " ('not be', 150433242),\n",
       " ('you are', 148097077),\n",
       " ('This is', 147052044),\n",
       " ('It is', 146170368),\n",
       " ('such as', 144817266),\n",
       " ('if you', 140746703),\n",
       " ('out of', 139365988)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_bigram.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_dist_unigram = calc_prob_distibution(counts_unigram)\n",
    "prob_dist_bigram = calc_prob_distibution(counts_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change Pwords to use P1w (the bigger dictionary) instead of Pword\n",
    "def prob_words(words):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product(prob_dist_unigram(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cond_prob_word(word, prev):\n",
    "    \"Conditional probability of word, given previous word.\"\n",
    "    bigram = prev + ' ' + word\n",
    "    if prob_dist_bigram(bigram) > 0 and prob_dist_unigram(prev) > 0:\n",
    "        return prob_dist_bigram(bigram) / prob_dist_unigram(prev)\n",
    "    else: # Average the back-off value and zero.\n",
    "        return prob_dist_unigram(word) / 2\n",
    "    \n",
    "def prob_words_improved(words, prev='<S>'):\n",
    "    \"The probability of a sequence of words, using bigram data, given prev word.\"\n",
    "    return product(cond_prob_word(w, (prev if (i == 0) else words[i-1]) )\n",
    "                                       for (i, w) in enumerate(words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.087644042127257e-05\n",
      "7.2594323333854714e-09\n"
     ]
    }
   ],
   "source": [
    "print(prob_words(words('the the the')))\n",
    "print(prob_words_improved(words('the the the')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why does the probability of the phrase go down with bigram word?\n",
    "\n",
    "The chances are of 'the the the' are vanishing small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5124331077955047e-07\n",
      "0.00012825557171799635\n"
     ]
    }
   ],
   "source": [
    "print(prob_words(words('of the same'))) #=> 3.5124331077955047e-07\n",
    "print(prob_words_improved(words('of the same'))) #=> 0.00012825557171799635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
