{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Exercises: Language Modeling\n",
    "====\n",
    "\n",
    "![](https://www.sri.com/sites/default/files/uploads/brains_languagetrans_istockphoto.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words Model\n",
    "----\n",
    "\n",
    "We take the words in a corpus to make a __generative model__ of language. \n",
    "\n",
    "We know that language is very complicated, but we can create a simplified model of language that captures part of the complexity. \n",
    "\n",
    "In the __bag of words__ model, we ignore the order of words, just count their frequency.  \n",
    "\n",
    "Think of it this way: take all the words from the text, and throw them into a bag.  Shake the bag, and then generating a sentence consists of pulling words out of the bag one at a time.  \n",
    "\n",
    "Chances are it won't be grammatical or sensible, but it will have words in roughly the right proportions.  \n",
    "\n",
    "Let's write a function to sample an *n* word sentence from a bag of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../corpora/the_kama_sutra.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def words(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'kama', 'sutra', 'of', 'vatsyayana']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karma = words(text)\n",
    "karma[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on', 'and', 'lovers', 'occasion', 'the']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.shuffle(karma)\n",
    "bag = karma\n",
    "bag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "#can import random instead of numpy random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(bag, n=10):\n",
    "    \"Sample a random n-word sentence from the model described by the bag of words.\"\n",
    "    return [choice(bag) for _ in range(n)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nails',\n",
       " 'pass',\n",
       " 'obey',\n",
       " 'woman',\n",
       " 'movements',\n",
       " 'king',\n",
       " 'assuring',\n",
       " 'pleasure',\n",
       " 'and',\n",
       " 'though']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX: There can't be a deterministic unit test since it is random function it should be something like...\n",
    "sample(bag) #=> 'intercourse attached he between his with things as phut to'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of ngram model is this? Why?\n",
    "\n",
    "1. unigram\n",
    "2. bigram\n",
    "3. trigram\n",
    "4. none of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Unigram model - words that are more represented in the bag have a higher chance of being picked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58751"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(karma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4487),\n",
      " ('of', 2957),\n",
      " ('and', 2224),\n",
      " ('to', 1560),\n",
      " ('a', 1478),\n",
      " ('her', 1081),\n",
      " ('is', 999),\n",
      " ('in', 980),\n",
      " ('should', 812),\n",
      " ('with', 717)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "counts = Counter(karma)\n",
    "pprint(counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5249"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that frequency for neverseen is zero\n",
    "counts['neverseen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  count\n",
      "there                 120\n",
      "are                   425\n",
      "common                11\n",
      "and                   2224\n",
      "neverseen             0\n",
      "words                 41\n"
     ]
    }
   ],
   "source": [
    "print('{0:20}  {1}'.format(\"word\", \"count\"))\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print('{0:20}  {1}'.format(word, counts[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  frequency\n",
      "the                   0.076\n",
      "are                   0.0072\n",
      "common                0.00019\n",
      "and                   0.038\n",
      "neverseen             0.0\n",
      "words                 0.0007\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate the frequency of the words\n",
    "\n",
    "print('{0:20}  {1}'.format(\"word\", \"frequency\"))\n",
    "for word in words('the are common and neverseen words'):\n",
    "    print('{0:20}  {1:.2}'.format(word, counts[word]/len(karma))) #divide by total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58751"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Turn that into a function\n",
    "def calc_prob_distibution(counter):\n",
    "    \"Calculate a probability distribution based on evidence from a Counter.\"\n",
    "    \n",
    "    def prob_distribution(string):\n",
    "        \n",
    "        return counter[string] / sum(counter.values())\n",
    "    return prob_distribution\n",
    "\n",
    "    \n",
    "    \n",
    "prob_distrubtion = calc_prob_distibution(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07637316811628739"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distrubtion(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert round(prob_distrubtion(\"the\"), 4) == 0.0764\n",
    "assert round(prob_distrubtion(\"with\"), 4) == 0.0122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, what is the probability of a *sequence* of words?  Use the definition of a joint probability:\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_1 w_2) \\ldots  \\times \\ldots P(w_n \\mid w_1 \\ldots w_{n-1})$\n",
    "\n",
    "The *bag of words* model assumes that each word is drawn from the bag *independently* of the others.  This gives us the wrong approximation:\n",
    "    \n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2) \\times P(w_3) \\ldots  \\times \\ldots P(w_n)$\n",
    "\n",
    "It is wrong but okay enough to move forward..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def product(iterable):\n",
    "    \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "def prob_words(words):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product(prob_distrubtion(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the the                     0.000445474\n",
      "the son                         7.79968e-06\n",
      "the son of a Brahman            3.02572e-12\n",
      "this is a neverbeforeseen word  0.0\n"
     ]
    }
   ],
   "source": [
    "phrases = ['the the the',\n",
    "         'the son',\n",
    "         'the son of a Brahman', \n",
    "         'this is a neverbeforeseen word']\n",
    "\n",
    "for phrase in phrases:\n",
    "    print('{0:30}  {1:.6}'.format(phrase, prob_words(words(phrase))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO: Why is `the the the` so likely? What would we have to add to our model to reduce the likelihood of nonsense phrases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The word the occurs very frequently by itself. Since we are only considering words by themselves,\n",
    "#the combination of the the the is the probability of the occuring times 3 (which is fairly high).\n",
    "# If you used bigrams, you would eliminate the probability of two the's occuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why is there zero probability for a phrase with a neverbeforseen word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In our training corpus, there is not the word neverbeforeseen. Therefore, this receives a probability of zero.\n",
    "#This , in turn, returns a product of all of these words to be zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Challenge Exercises\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mo' Data, Mo' Better\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move up from millions to *billions and billions* of words.  \n",
    "\n",
    "Once we have that amount of data, we can start to look at two word sequences, without them being too sparse.  \n",
    "\n",
    "We happen to have data files available in the format of `\"word \\t count\"`, and bigram data in the form of `\"word1 word2 \\t count\"`.  Let's arrange to read them in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_counts(filename, sep='\\t'):\n",
    "    \"\"\"Return a Counter initialized from key-value pairs, \n",
    "    one on each line of filename.\"\"\"\n",
    "    C = Counter()\n",
    "    for line in open(filename):\n",
    "        key, count = line.split(sep)\n",
    "        C[key] = int(count)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333333\n",
      "286358\n"
     ]
    }
   ],
   "source": [
    "counts_unigram = load_counts('../../corpora/unigram_word_counts.txt')\n",
    "counts_bigram = load_counts('../../corpora/bigram_word_counts.txt')\n",
    "\n",
    "print(len(counts_unigram))\n",
    "print(len(counts_bigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: What is the total number of unigrams and bigrams in the?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are 333,333 unigrams and 286,358 bigrams for a total of 619,691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619691"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "333333+286358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23135851162),\n",
       " ('of', 13151942776),\n",
       " ('and', 12997637966),\n",
       " ('to', 12136980858),\n",
       " ('a', 9081174698),\n",
       " ('in', 8469404971),\n",
       " ('for', 5933321709),\n",
       " ('is', 4705743816),\n",
       " ('on', 3750423199),\n",
       " ('that', 3400031103),\n",
       " ('by', 3350048871),\n",
       " ('this', 3228469771),\n",
       " ('with', 3183110675),\n",
       " ('i', 3086225277),\n",
       " ('you', 2996181025)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_unigram.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the', 2766332391),\n",
       " ('in the', 1628795324),\n",
       " ('to the', 1139248999),\n",
       " ('on the', 800328815),\n",
       " ('for the', 692874802),\n",
       " ('and the', 629726893),\n",
       " ('to be', 505148997),\n",
       " ('is a', 476718990),\n",
       " ('with the', 461331348),\n",
       " ('from the', 428303219),\n",
       " ('by the', 417106045),\n",
       " ('at the', 416201497),\n",
       " ('of a', 387060526),\n",
       " ('in a', 364730082),\n",
       " ('will be', 356175009)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_bigram.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Bigram Model\n",
    "-----\n",
    "\n",
    "A less-wrong approximation:\n",
    "    \n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_2) \\ldots  \\times \\ldots P(w_n \\mid w_{n-1})$\n",
    "\n",
    "This is called the *bigram* model, and is equivalent to taking a text, cutting it up into slips of paper with two words on them, and having multiple bags, and putting each slip into a bag labelled with the first word on the slip.  Then, to generate language, we choose the first word from the original single bag of words, and chose all subsequent words from the bag with the label of the previously-chosen word.\n",
    "\n",
    "Let's start by defining the probability of a single discrete event, given evidence stored in a Counter:\n",
    "\n",
    "Recall that the less-wrong bigram model approximation to English is:\n",
    "    \n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_2) \\ldots  \\times \\ldots P(w_n \\mid w_{n-1})$\n",
    "\n",
    "where the conditional probability of a word given the previous word is defined as:\n",
    "\n",
    "$P(w_n \\mid w_{n-1}) = P(w_{n-1}w_n) / P(w_{n-1}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_dist_unigram = calc_prob_distibution(counts_unigram)\n",
    "prob_dist_bigram = calc_prob_distibution(counts_bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588124220187"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(counts_unigram.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03933837507090547"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist_unigram('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012242832903921587"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist_bigram('of the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change function to use the bigger dictionary\n",
    "def prob_words(words):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product(prob_dist_unigram(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.087644042127257e-05"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "prob_words(['the','the','the'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cond_prob_word(word, prev):\n",
    "    \"Conditional probability of word, given previous word.\"\n",
    "    bigram = prev + ' ' + word\n",
    "    if prob_dist_bigram(bigram) > 0 and prob_dist_unigram(prev) > 0:\n",
    "        \n",
    "        return prob_dist_bigram(bigram) / prob_dist_unigram(prev)\n",
    "    else: # Average the back-off value and zero.\n",
    "        return prob_dist_unigram(word) / 2\n",
    "\n",
    "# TODO: Finish the prob_words_two function\n",
    "def prob_words_bigram(words, prev='<S>'):\n",
    "    \"The probability of a sequence of words, using bigram data, given prev word.\"\n",
    "    #print(len(words))\n",
    "    cond_prob = []\n",
    "    #prob_words(words(phrase))\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        #print(i,'i')\n",
    "        if i == 0:\n",
    "            cond_prob.append(cond_prob_word(words[i],prev))\n",
    "        else:\n",
    "            cond_prob.append(cond_prob_word(words[i],words[i-1]))\n",
    "    \n",
    "\n",
    "    \n",
    "    #print(cond_prob)\n",
    "    print(product(cond_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5474709460900279"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "cond_prob_word('the','of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2594323333854714e-09\n"
     ]
    }
   ],
   "source": [
    "prob_words_bigram(words('the the the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.087644042127257e-05\n",
      "7.2594323333854714e-09\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prob_words(words('the the the'))) #=> 6.087644042127257e-05\n",
    "print(prob_words_bigram(words('the the the'))) #=> 7.2594323333854714e-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why does the probability of this phrase go down with bigram word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5124331077955047e-07\n",
      "0.00012825557171799635\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prob_words(words('of the same'))) #=> 6.087644042127257e-05\n",
    "print(prob_words_bigram(words('of the same')))  #=> 0.00012825557171799635"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why does the probability of this phrase go way up with bigram word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bigram takes into account the probabilities of pairs of words. With only a unigram model, \n",
    "#you only consider the probability of individual words and not pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [nlp]",
   "language": "python",
   "name": "Python [nlp]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
