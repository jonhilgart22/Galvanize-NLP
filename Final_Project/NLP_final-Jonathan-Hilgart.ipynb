{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Choose Your Own Adventure Story\n",
    "\n",
    "- You are about to embark on a choosen your own adventure story with none other than Donald Trump! You have the option to inhabit the world of Alice in Wonderland, The Grimms Fairy Tales, or Ulysses. As you move throughout the story, think about your next decision carefully...danger awaits around every turn!\n",
    "\n",
    "![alt text](choose_your_own_adventure.png \"Title\")\n",
    "\n",
    "> Stories to choose from\n",
    "- Sherlock\n",
    "- Alice in Wonderland\n",
    "- Ulysses\n",
    "\n",
    "#### Resources\n",
    "> Trump speeches https://github.com/ryanmcdermott/trump-speeches\n",
    "\n",
    "> TFIDF http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity\n",
    "\n",
    "> Mad Libs inspiration: https://www.pinterest.com/explore/mad-libs/\n",
    "\n",
    "> word2vec https://rare-technologies.com/word2vec-tutorial/\n",
    "\n",
    "\n",
    "#### How to play this game\n",
    "\n",
    "- This choose your own adventure story works as follows. I have defined four sets of 'story chunks'. You can think of these story chunks as scaffolding for a mad libs style game (i.e. there are variables to input nouns, verbs, proper nouns, named entities ...etc. First, before the user starts the game, I generated unigram, bigram, and trigram word probabilities off of a Donald Trump speech corpus. \n",
    "- Next, the user picks a story (a world in inhabit). After this, I perform Part Of Speech (POS) and Named Entity Recognition (NER) to extract the relevant nouns, verbs, proper nouns ..etc from the story. \n",
    "- After this, the user selects three items to bring with them through out story.\n",
    "- As the user proceeds, he/she will have to enter a sentence incorporating one of the items brought with them in order to decide what part of the story to visit next.\n",
    "- This user sentence is used as a query for a TF-IDF information retreival task. In addition, word2vec is performed on the query and story chunks to determine the most similar word to the ones entered by the user.\n",
    "- Finally, the user continues to proceed until the reach the end or die.\n",
    "\n",
    "#### Architecture of system\n",
    "![alt text](architecture.png \"Title\")\n",
    "\n",
    "#### Notes\n",
    "- The word2vec model is not very stable due to the small size of the training corpus (the various story chunks). We could train on a larger corpora, but I am more interested in the similarity between the user query and current words in the story chunk.\n",
    "- There are four sections to the game. Everyone will reach the thirs section, and then it depends on your choice of what to do next if you make it to the fourth section.\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from functools import reduce\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from spacy.en import English\n",
    "## The sentence generator module contains a trigram model for sentence generation\n",
    "from sentence_generator import SentenceGenerator\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from story_chunks import place_of_story\n",
    "from sklearn.metrics import accuracy_score\n",
    "from Evaluation_Metrics_word2vec import accuracy_score_test,word2vec\n",
    "import seaborn as sns\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which story would you like to read? You can choose Grimms fairy tales, Alice in Wonderland, or Ulysses.\n",
      "Please spell the name correctly.\n",
      "Which story would you like to read? You can choose Grimms fairy tales, Alice in Wonderland, or Ulysses.Alice in Wonderland\n"
     ]
    }
   ],
   "source": [
    "# First, we need to decide which world the user would like to inhabit\n",
    "story_names = ['Grimms fairy tales','Alice in Wonderland','Ulysses']\n",
    "while True:\n",
    "    story = input(\"Which story would you like to read? You can choose Grimms fairy tales, Alice in Wonderland, or Ulysses.\")\n",
    "    if story not in story_names:\n",
    "        print('Please spell the name correctly.')\n",
    "    if story in story_names:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Open Trump speeches to create probabilistic sentence generation\n",
    "with open(\"speeches.txt\") as f:\n",
    "        text_trump = f.read()\n",
    "#Clean trump text\n",
    "text= re.sub(r'[-!@#$%^&*()\\n_]+',' ',text_trump)\n",
    "text = text.lower() ## lower the letters to increase the number of matches\n",
    "#Token the Trump words, count the frequency of each token, and create a unigram, bigram, and trigram dictionary\n",
    "trump_story = SentenceGenerator(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Open the appropriate story based upon the user input\n",
    "if story =='Alice in Wonderland':\n",
    "    with open(\"alice_in_wonderland_copy.txt\") as f:\n",
    "        text_s = f.read()\n",
    "elif story =='Grimms fairy tales':\n",
    "    with open(\"grimms_fairy_tales.txt\") as f:\n",
    "        text_s = f.read()\n",
    "elif story =='Ulysses':\n",
    "    with open(\"ulysses_copy.txt\") as f:\n",
    "        text_s = f.read()\n",
    "#Clean the text. Remove all punctuation except for periods, question marks, and exclamation points.\n",
    "punctuation ='[ \\ * \\ [ - _ , : ; @ # $ % ^ & * ( ) \\]  \\n \\']'.split(' ')\n",
    "text_t = re.sub(r'[-!@#$%^&*()\\n_]+',' ',text_s)\n",
    "blob_text_story = TextBlob(text_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#POS for the story ## JJ - adjective ##NN - noun ##NNS - common noun plural ## NNP - proper noun plural #VB - verb\n",
    "pos_entities = defaultdict(list)\n",
    "for word,pos in blob_text_story.tags:\n",
    "    if pos != \"\":\n",
    "        pos_entities[pos].append(str(word).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NER for the story characters and places - Entites {'GPE', 'CARDINAL', 'PRODUCT',\n",
    "#'DATE', 'ORG', 'WORK_OF_ART', 'NORP', 'QUANTITY', 'TIME', 'PERSON', 'ORDINAL', 'MONEY', 'LOC', 'LANGUAGE', 'FAC'}\n",
    "# takes ~ 2 minutes\n",
    "nlp = English()\n",
    "ner_story_tokens = nlp(text_t)\n",
    "possible_entities = defaultdict(list)\n",
    "for token in ner_story_tokens:\n",
    "    if token.ent_type_ != \"\":\n",
    "        if str(token) in possible_entities.values():\n",
    "            pass\n",
    "        else:\n",
    "            if len(token)<3: ## check that it is an actual entity \n",
    "                pass\n",
    "            else:\n",
    "                possible_entities[token.ent_type_].append(str(token).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## find the most common entities used in the story\n",
    "people_counter = Counter(possible_entities['PERSON'])\n",
    "place_counter = Counter(possible_entities['GPE'])\n",
    "org_counter = Counter(possible_entities['ORG'])\n",
    "language_counter = Counter(possible_entities['LANGUAGE'])\n",
    "product_counter = Counter(possible_entities['PRODUCT'])\n",
    "### find the most common POS for different words\n",
    "single_noun_com_counter= Counter(pos_entities['NN'])\n",
    "plural_noun_com_counter = Counter(pos_entities['NNS'])\n",
    "verb_counter= Counter(pos_entities['VB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have a text generator for Trump and named entity recognition / part of speech tagging completed for the story; now, move onto the actual adventure!\n",
    "- Count the most common occurance of nouns, verbs, named entities to represent the major variables that will be plugged into our mad libs scaffolding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### need to keep track of the different entities used and in what order\n",
    "protagonist=people_counter.most_common(1)[0][0].lower()\n",
    "antagonist = people_counter.most_common(2)[1][0].lower()\n",
    "place_one= place_counter.most_common(1)[0][0].lower()\n",
    "place_two = place_counter.most_common(2)[1][0].lower()\n",
    "language_one = language_counter.most_common(1)[0][0].lower()\n",
    "single_noun_one =single_noun_com_counter.most_common(1)[0][0].lower()\n",
    "single_noun_two = single_noun_com_counter.most_common(2)[1][0].lower()\n",
    "plural_noun_one = plural_noun_com_counter.most_common(1)[0][0].lower()\n",
    "plural_noun_two = plural_noun_com_counter.most_common(2)[1][0].lower()\n",
    "verb_one = verb_counter.most_common(1)[0][0].lower()\n",
    "verb_two = verb_counter.most_common(2)[1][0].lower()\n",
    "verb_three = verb_counter.most_common(3)[2][0].lower()\n",
    "#utility_item_chosen, funny_item_chosen, transportation_item_chosen\n",
    "utility_items='pocketknife flashlight'.split(' ')\n",
    "funny_items='half-eaten-sandwich broken-lightbulb'.split(' ')\n",
    "transportation_items = 'skateboard bike'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to a choose your own adventure story!\n",
      " Below you will pick a story, and you will explore that world with a campanion. Throughout the story, you will have different options for next steps to take. Your goal is to choose the options that lead you safely on your adventure.  However, be careful! Danger awaits around every turn.\n"
     ]
    }
   ],
   "source": [
    "print('Welcome to a choose your own adventure story!\\n Below you will pick a story, and you will explore that world with a campanion. \\\n",
    "Throughout the story, you will have different options for next steps to take. \\\n",
    "Your goal is to choose the options that lead you safely on your adventure.  \\\n",
    "However, be careful! Danger awaits around every turn.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You awake and look around \"Hey, I think I recognize this place\", you think to yourself. You realize that you are sitting down on something, you can not quite tell what, but you feel strangely awake.You turn to your right and see hans from Grimms fairy tales. On your left, you see Donald Trump. You wonder where you are and how this all happened, but before you can think too much Trump turns to you and says  Hopefully have never thought this was on the team . You do about isis . She was totally unique .  Well that was weird you think to yourself. Shaking it off, you turn to hans who says,         \"Welcome to Grimms fairy tales! We are excited to have you and your friend explore our         world. Before we start what do you want to bring with you on your         journey? 'Please pick one from each category,' instructes hans.\n",
      "\n",
      "\n",
      "['pocketknife', 'flashlight']\n",
      "Which item would you like?pocketknife\n",
      "\n",
      "['half-eaten-sandwich', 'broken-lightbulb']\n",
      "Which of these would you like?half-eaten-sandwich\n",
      "\n",
      "['skateboard', 'bike']\n",
      "Which of these would you like?skateboard\n"
     ]
    }
   ],
   "source": [
    "###### The first section of the story   \n",
    "print('You awake and look around \"Hey, I think I recognize this place\", you think to yourself. You realize \\\n",
    "that you are sitting down on something, you can not quite tell what, but you feel strangely awake. \\\n",
    "You turn to your right and see {} from {}. On your left, you see \\\n",
    "Donald Trump. You wonder where you are and how this all happened, but before you can think too much \\\n",
    "Trump turns to you and says '.format(protagonist,story),\\\n",
    "      trump_story.sentence_generate(3),\\\n",
    "        'Well that was weird you think to yourself. Shaking it off, you turn to {} who says, \\\n",
    "        \"Welcome to {}! We are excited to have you and your friend explore our \\\n",
    "        world. Before we start what do you want to bring with you on your \\\n",
    "        journey?'.format(protagonist,story),\\\n",
    "        \"'Please pick one from each category,' instructes {}.\".format(protagonist))\n",
    "print()## keep track of the options chosen\n",
    "while True:\n",
    "    print()\n",
    "    print(utility_items)\n",
    "    utility_item_chosen = input(\"Which item would you like?\")\n",
    "    if utility_item_chosen in utility_items:\n",
    "        break\n",
    "    else:\n",
    "        print('Please spell the word correctly without the quotes')\n",
    "while True:\n",
    "    print()\n",
    "    print(funny_items)\n",
    "    funny_item_chosen = input(\"Which of these would you like?\")\n",
    "    if funny_item_chosen in funny_items:\n",
    "        break\n",
    "    else:\n",
    "        print('Please spell the word correctly without the quotes')\n",
    "while True:\n",
    "    print()\n",
    "    print(transportation_items)\n",
    "    trans_item_chosen = input('Which of these would you like?')\n",
    "    if trans_item_chosen in transportation_items:\n",
    "        break\n",
    "    else:\n",
    "        print('Please spell the word correctly without the quotes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next    incorporating an item you have choosen.If you want to see the items you have, type items.skateboard going away now\n"
     ]
    }
   ],
   "source": [
    "#First choice by the user\n",
    "choice1=[]\n",
    "while True:\n",
    "    choice = input('Please write a sentence for what you would like to do next\\\n",
    "    incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "    if choice =='items':\n",
    "        print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "    else:\n",
    "        choice1.append(choice)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After each block of story, the sentence entered by the user will be used by an IR system (tf-idf with cosine similarity) to pick the  next part of the story.\n",
    "- In addition, word2vec will pull of the more similar words in the current story chunk to the words entered by a user (assuming the words entered by the user are in the story chunk. If not, they are not used for the word2vec model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the first section of possible texts for the story\n",
    "storychunk_one = place_of_story(1,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(2),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three) #protagonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words most similar to the query words added together : ['skateboard', 'going', 'now']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('oh', 0.36061275005340576),\n",
       " ('to', 0.23720213770866394),\n",
       " ('notice', 0.21844087541103363),\n",
       " ('was', 0.21785952150821686),\n",
       " ('!', 0.21304306387901306),\n",
       " ('lightblub', 0.2106826901435852),\n",
       " ('have', 0.19018599390983582),\n",
       " ('really', 0.18946628272533417),\n",
       " ('state', 0.18530911207199097),\n",
       " ('before', 0.17707346379756927)]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec(storychunk_one,choice1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the next story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"It is time to explore!\" you announce to hans . With that, you jump on your skateboard, before realizing that Trump was not going to fit on your board. \"Hmmm,\" you think. Maybe I better try something else. What do you do next?'"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF with cosine similarity\n",
    "tfidf_one = TfidfVectorizer() \n",
    "tf_idf_storyone= tfidf_one.fit_transform(storychunk_one) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice1_tfidf = tfidf_one.transform(choice1) ## turn the user sentence into a vector\n",
    "cosine_sim_one = linear_kernel(tf_idf_storyone,choice1_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "re.sub(r'(\\t)','',storychunk_one[cosine_sim_one.argsort()[::-1][0]]) ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next     incorporating an item you have choosen.If you want to see the items you have, type items.let's go explore the nearby caves with Trump\n"
     ]
    }
   ],
   "source": [
    "choice2=[]\n",
    "while True:\n",
    "    choice = input('Please write a sentence for what you would like to do next \\\n",
    "    incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "    if choice =='items':\n",
    "        print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "    else:\n",
    "        choice2.append(choice)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' You decide to take out your pocketknife and use it to carve the man nearby with your initials.Trump smiles with a look of approval and says Cory . Time magazine . So here’s what they did a very tough night looking at the line and they will do what’s right .  .  \"Was he always this elegant?\" you think to yourself.   Now that you you will be remembered forever from your carving, what do you want to do next?'"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the second section of possible texts for the story\n",
    "storychunk_two = place_of_story(2,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three) \n",
    "tfidf_two = TfidfVectorizer()  #create a model\n",
    "tf_idf_storytwo= tfidf_two.fit_transform(storychunk_two) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice2_tfidf = tfidf_two.transform(choice2) ## turn the user sentence into a vector\n",
    "cosine_sim_two = linear_kernel(tf_idf_storytwo,choice2_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "re.sub(r'(\\t)','',storychunk_two[cosine_sim_two.argsort()[::-1][0]]) ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words most similar to the query words added together : ['go', 'the', 'nearby', 'with', 'trump']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dear', 0.21185657382011414),\n",
       " ('tonight', 0.20742258429527283),\n",
       " ('search', 0.20632140338420868),\n",
       " ('fresh', 0.20057904720306396),\n",
       " ('nightmare', 0.190053790807724),\n",
       " ('from', 0.184449702501297),\n",
       " ('smiling', 0.18140283226966858),\n",
       " ('biking', 0.17914992570877075),\n",
       " ('very', 0.17106202244758606),\n",
       " ('end', 0.170486181974411)]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top related words for story chunk two\n",
    "word2vec(storychunk_two,choice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next     incorporating an item you have choosen.If you want to see the items you have, type items.let's eat our sandwich\n"
     ]
    }
   ],
   "source": [
    "choice3=[]\n",
    "while True:\n",
    "    choice = input('Please write a sentence for what you would like to do next \\\n",
    "    incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "    if choice =='items':\n",
    "        print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "    else:\n",
    "        choice3.append(choice)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You quickly take out what is left of your half-eaten-sandwich and show it to hans.  \"Good,\" sayd hans, \"We can use this to pay off gretel and get you to the man\".   You wonder where that is, or who gretel is, but you follow hans. What should you do now?'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the third section of possible texts for the story\n",
    "storychunk_three = place_of_story(3,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(4),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three) \n",
    "\n",
    "tfidf_three = TfidfVectorizer()  #create a model\n",
    "tf_idf_storythree= tfidf_three.fit_transform(storychunk_three) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice3_tfidf = tfidf_three.transform(choice3) ## turn the user sentence into a vector\n",
    "cosine_sim_three = linear_kernel(tf_idf_storythree,choice3_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "third_section = re.sub(r'(\\t)','',storychunk_three[cosine_sim_three.argsort()[::-1][0]] )\n",
    "third_section ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words most similar to the query words added together : ['our']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('at', 0.3092227578163147),\n",
       " ('hans', 0.2286866158246994),\n",
       " ('realizing', 0.2165977954864502),\n",
       " ('lightsaber', 0.1943700760602951),\n",
       " ('low', 0.19393713772296906),\n",
       " ('conceding', 0.19319508969783783),\n",
       " ('people', 0.1905955672264099),\n",
       " ('you', 0.18310847878456116),\n",
       " ('but', 0.17968755960464478),\n",
       " ('a', 0.17562904953956604)]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top related words for story chunk three\n",
    "word2vec(storychunk_three,choice3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next         incorporating an item you have choosen.If you want to see the items you have, type items.run away to the far land\n"
     ]
    }
   ],
   "source": [
    "if 'dead' in third_section:\n",
    "    print('You died with Trump by your side. Better luck next time!')\n",
    "elif 'died' in third_section:\n",
    "    print('You died with Trump by your side. Better luck next time!')\n",
    "else:\n",
    "    choice4=[]\n",
    "    while True:\n",
    "        choice = input('Please write a sentence for what you would like to do next \\\n",
    "        incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "        if choice =='items':\n",
    "            print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "        else:\n",
    "            choice4.append(choice)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth story chunk (if you make it this far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"Congratulations!\" says hans \"You defeated gretel and survived Grimms fairy tales. Best of luck in your future adventures\" '"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The fourth chunck - Only go here if the user made it here\n",
    "storychunk_four = place_of_story(4,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(2),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story) \n",
    "\n",
    "tfidf_four = TfidfVectorizer()  #create a model\n",
    "tf_idf_storyfour= tfidf_four.fit_transform(storychunk_four) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice4_tfidf = tfidf_four.transform(choice4) ## turn the user sentence into a vector\n",
    "cosine_sim_four = linear_kernel(tf_idf_storyfour,choice4_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "fourth_section = re.sub(r'(\\t)','',storychunk_four[cosine_sim_four.argsort()[::-1][0]] )\n",
    "fourth_section ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words most similar to the query words added together : []\n"
     ]
    }
   ],
   "source": [
    "## Top related words for story chunk four -- only if you have input for choice 4\n",
    "word2vec(storychunk_four,choice4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The secret to surviving is using the half eaten sandwich at the third story section :). Now, let us test the accuracy of the IR system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "> Accuracy\n",
    "\n",
    "- To evaluate our system, we want to look at the sentence entered by our users that contains an item they choose (i.e. bike) and pick the response that has that item. Since there is only one correct answer for each query, we will look at the average accuracy using each item over a number of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_chunk_one = place_of_story(1,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_chunk_two = place_of_story(2,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_chunk_three = place_of_story(3,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_test_one_queries = [['pocketknife'],\\\n",
    "                            ['I like to run with my pocketknife'],\\\n",
    "                            ['This is a flashy fun way to show how cool you are with friends pocketknife'],\\\n",
    "                           ['Do you know who I am that I love to watch Trump with my pocketknife?'],\\\n",
    "                           ['This is incredible!\\\n",
    "                           I love to carve wood and eat food with my own pocketknife even though you know Trump\\\n",
    "                           has a way with words!']]\n",
    "\n",
    "list_of_test_two_queries =[['half-eaten-sandwich'],\n",
    "                          ['I like to run around the town with my half-eaten-sandwich'],\n",
    "                          [\"Wow, he really has a way with words with your half-eaten-sandwich\"],\n",
    "                          ['asdf asdf sandwich asdfa'],\n",
    "                          ['This is lightsaber battle run fight half-eaten-sandwich']]\n",
    "\n",
    "list_of_test_three_queries = [['bike'],\n",
    "                             ['i like to ride my bicycle i like to ribe my bike'],\n",
    "                             ['run away to the furtherst point that you can with your bike'],\n",
    "                             ['looing at the moon and the stars and trump overhead you jump on the bike'],\n",
    "                             ['Running, jumping, biking, with your bike along side eating, swimming, walking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The acuracy is', 0.8, 'The query that failed was :', [['This is incredible!                           I love to carve wood and eat food with my own pocketknife even though you know Trump                           has a way with words!']])\n",
      "('The acuracy is', 1.0)\n",
      "('The acuracy is', 0.8, 'The query that failed was :', [['This is a flashy fun way to show how cool you are with friends pocketknife']])\n"
     ]
    }
   ],
   "source": [
    "#First chuck\n",
    "print(accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife'))\n",
    "txt,num_one,quertxt,query_one = accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife')\n",
    "q_one = TextBlob(query_one[0][0])\n",
    "len_query_one = sum(q_one.word_counts.values())\n",
    "total_avg_len_query_one = np.mean([sum(TextBlob(i[0][0]).word_counts.values()) for i in list_of_test_one_queries])\n",
    "#Second Chucnk\n",
    "print(accuracy_score_test(list_of_test_one_queries,test_chunk_two,'pocketknife'))\n",
    "txt_two,num_two,quertxt,query_two = accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife')\n",
    "q_two = TextBlob(query_two[0][0])\n",
    "len_query_two = sum(q_two.word_counts.values())\n",
    "#Third chunk\n",
    "print(accuracy_score_test(list_of_test_one_queries,test_chunk_three,'pocketknife'))\n",
    "txt_three,num_three,quertxt,query_three = accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife')\n",
    "q_three = TextBlob(query_three[0][0])\n",
    "len_query_three = sum(q_three.word_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The acuracy is', 0.8, 'The query that failed was :', [['Wow, he really has a way with words with your half-eaten-sandwich']])\n",
      "('The acuracy is', 1.0)\n",
      "('The acuracy is', 1.0)\n"
     ]
    }
   ],
   "source": [
    "#First chuck\n",
    "print(accuracy_score_test(list_of_test_two_queries,test_chunk_one,'half-eaten-sandwich'))\n",
    "    \n",
    "#Second Chucnk\n",
    "print(accuracy_score_test(list_of_test_two_queries,test_chunk_two,'half-eaten-sandwich'))\n",
    "    \n",
    "#Third chunk\n",
    "print(accuracy_score_test(list_of_test_two_queries,test_chunk_three,'half-eaten-sandwich'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The acuracy is', 0.8, 'The query that failed was :', [['run away to the furtherst point that you can with your bike']])\n",
      "('The acuracy is', 0.6, 'The query that failed was :', [['i like to ride my bicycle i like to ribe my bike'], ['looing at the moon and the stars and trump overhead you jump on the bike']])\n",
      "('The acuracy is', 0.8, 'The query that failed was :', [['Running, jumping, biking, with your bike along side eating, swimming, walking']])\n"
     ]
    }
   ],
   "source": [
    "#First chuck\n",
    "print(accuracy_score_test(list_of_test_three_queries,test_chunk_one,'bike'))\n",
    "    \n",
    "#Second Chucnk\n",
    "print(accuracy_score_test(list_of_test_three_queries,test_chunk_two,'bike'))\n",
    "    \n",
    "#Third chunk\n",
    "print(accuracy_score_test(list_of_test_three_queries,test_chunk_three,'bike'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In general, our IR system, TF-IDF with cosine similarity, works pretty well unless the query closely resembles a different story chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
