{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Choose your own adventure story\n",
    "\n",
    "- You are about to embark on a choosen your own adventure story with none other than Donal Trump! You have the option to inhabit the world of Alice in Wonderland, The Grimms Fairy Tales, or Ulysses. As you move throughout the story, think about your next decision carefully...danger awaits around every turn!\n",
    "\n",
    "![alt text](choose_your_own_adventure.png \"Title\")\n",
    "\n",
    "> Stories to choose from\n",
    "- Sherlock\n",
    "- Alice in Wonderland\n",
    "- Ulysses\n",
    "\n",
    "#### Resources\n",
    "> Trump speeches https://github.com/ryanmcdermott/trump-speeches\n",
    "\n",
    "> TFIDF http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity\n",
    "\n",
    "> Mad Libs inspiration: https://www.pinterest.com/explore/mad-libs/\n",
    "\n",
    "#### Architecture of system\n",
    "\n",
    "![alt text](architecture.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from functools import reduce\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from spacy.en import English\n",
    "## The sentence generator module contains a trigram model for sentence generation\n",
    "from sentence_generator import SentenceGenerator\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from story_chunks import place_of_story\n",
    "from sklearn.metrics import accuracy_score\n",
    "from Evaluation_Metrics import accuracy_score_test\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which story would you like to read? You can choose Grimms fairy tales, Alice in Wonderland, or Ulysses.Grimms fairy tales\n"
     ]
    }
   ],
   "source": [
    "# First, we need to decide which world the user would like to inhabit\n",
    "story_names = ['Grimms fairy tales','Alice in Wonderland','Ulysses']\n",
    "while True:\n",
    "    story = input(\"Which story would you like to read? You can choose Grimms fairy tales, Alice in Wonderland, or Ulysses.\")\n",
    "    if story not in story_names:\n",
    "        print('Please spell the name correctly.')\n",
    "    if story in story_names:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Open Trump speeches to predict sentences off of\n",
    "with open(\"speeches.txt\") as f:\n",
    "        text_trump = f.read()\n",
    "#Clean trump text\n",
    "text= re.sub(r'[-!@#$%^&*()\\n_]+',' ',text_trump)\n",
    "text = text.lower() ## lower the letters to increase the number of matches\n",
    "#Token the Trump words, count the frequency of each token, and create a unigram, bigram, and trigram dictionary\n",
    "trump_story = SentenceGenerator(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Open the appropriate story based upon the user input\n",
    "if story =='Alice in Wonderland':\n",
    "    with open(\"alice_in_wonderland_copy.txt\") as f:\n",
    "        text_s = f.read()\n",
    "elif story =='Grimms fairy tales':\n",
    "    with open(\"grimms_fairy_tales.txt\") as f:\n",
    "        text_s = f.read()\n",
    "elif story =='Ulysses':\n",
    "    with open(\"ulysses_copy.txt\") as f:\n",
    "        text_s = f.read()\n",
    "#Clean the text. Remove all punctuation except for periods, question marks, and exclamation points.\n",
    "punctuation ='[ \\ * \\ [ - _ , : ; @ # $ % ^ & * ( ) \\]  \\n \\']'.split(' ')\n",
    "text_t = re.sub(r'[-!@#$%^&*()\\n_]+',' ',text_s)\n",
    "\n",
    "blob_text_story = TextBlob(text_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#POS for the story ## JJ - adjective ##NN - noun ##NNS - common noun plural ## NNP - proper noun plural #VB - verb\n",
    "pos_entities = defaultdict(list)\n",
    "for word,pos in blob_text_story.tags:\n",
    "    if pos != \"\":\n",
    "        pos_entities[pos].append(str(word).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NER for the story characters and places - Entites {'GPE', 'CARDINAL', 'PRODUCT',\n",
    "#'DATE', 'ORG', 'WORK_OF_ART', 'NORP', 'QUANTITY', 'TIME', 'PERSON', 'ORDINAL', 'MONEY', 'LOC', 'LANGUAGE', 'FAC'}\n",
    "# takes ~ 2 minutes\n",
    "nlp = English()\n",
    "ner_story_tokens = nlp(text_t)\n",
    "possible_entities = defaultdict(list)\n",
    "for token in ner_story_tokens:\n",
    "    if token.ent_type_ != \"\":\n",
    "        if str(token) in possible_entities.values():\n",
    "            pass\n",
    "        else:\n",
    "            if len(token)<3: ## check that it is an actual entity \n",
    "                pass\n",
    "            else:\n",
    "                possible_entities[token.ent_type_].append(str(token).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## find the most common entities used in the story\n",
    "people_counter = Counter(possible_entities['PERSON'])\n",
    "place_counter = Counter(possible_entities['GPE'])\n",
    "org_counter = Counter(possible_entities['ORG'])\n",
    "language_counter = Counter(possible_entities['LANGUAGE'])\n",
    "product_counter = Counter(possible_entities['PRODUCT'])\n",
    "### find the most common POS for different words\n",
    "single_noun_com_counter= Counter(pos_entities['NN'])\n",
    "plural_noun_com_counter = Counter(pos_entities['NNS'])\n",
    "verb_counter= Counter(pos_entities['VB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have a text generator for Trump and named entity recognition / part of speech tagging completed for the story; now, move onto the actual adventure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### need to keep track of the different entities used and in what order, # put in items here\n",
    "#story - variable for story name\n",
    "#Counters below\n",
    "protagonist=people_counter.most_common(1)[0][0].lower()\n",
    "antagonist = people_counter.most_common(2)[1][0].lower()\n",
    "place_one= place_counter.most_common(1)[0][0].lower()\n",
    "place_two = place_counter.most_common(2)[1][0].lower()\n",
    "language_one = language_counter.most_common(1)[0][0].lower()\n",
    "single_noun_one =single_noun_com_counter.most_common(1)[0][0].lower()\n",
    "single_noun_two = single_noun_com_counter.most_common(2)[1][0].lower()\n",
    "plural_noun_one = plural_noun_com_counter.most_common(1)[0][0].lower()\n",
    "plural_noun_two = plural_noun_com_counter.most_common(2)[1][0].lower()\n",
    "verb_one = verb_counter.most_common(1)[0][0].lower()\n",
    "verb_two = verb_counter.most_common(2)[1][0].lower()\n",
    "verb_three = verb_counter.most_common(3)[2][0].lower()\n",
    "#utility_item_chocen, funny_item_chosen, transportation_item_chosen\n",
    "utility_items='pocketknife flashlight'.split(' ')\n",
    "funny_items='half-eaten-sandwich broken-lightbulb'.split(' ')\n",
    "transportation_items = 'skateboard bike'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to a choose your own adventure story!\n",
      " Below you will pick a story, and you will explore that world with a fellow campanion.Throughout the story, you will have different options for next steps to take. Your goal is to choose the options that lead you safely on your adventure.  However, be careful! Danger awaits around every turn.\n"
     ]
    }
   ],
   "source": [
    "print('Welcome to a choose your own adventure story!\\n Below you will pick a story, and you will explore that world with a fellow campanion.\\\n",
    "Throughout the story, you will have different options for next steps to take. \\\n",
    "Your goal is to choose the options that lead you safely on your adventure.  \\\n",
    "However, be careful! Danger awaits around every turn.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You awake and look around \"Hey, I think I recognize this place\", you think to yourself. You realize that you are sitting down on something, you can not quite tell what, but you feel strangely awake.You turn to your right and see hans from Grimms fairy tales. On your left, you see Donald Trump. You wonder where you are and how this all happened, but before you can think too much Trump turns to you and says  She violated section so and so many things we’re going to die.’ ‘oh shut up , makes a lot of people think i’m going to get in . I could even save more . But it has been a lot of things , without any effective plan for victory with the devaluations of so badly , and we are and with all of these areas have still never recovered .  Well that was weird you think to yourself. Shaking it off, you turn to hans who says,         \"Welcome to Grimms fairy tales! We are excited to have you and your friend explore our         world. Before we start what do you want to bring with you on your         journey? 'Please pick one from each category,' instructes hans.\n",
      "\n",
      "\n",
      "['pocketknife', 'flashlight']\n",
      "Which item would you like?flashlight\n",
      "\n",
      "['half-eaten-sandwich', 'broken-lightbulb']\n",
      "Which of these would you like?half-eaten-sandwich\n",
      "\n",
      "['skateboard', 'bike']\n",
      "Which of these would you like?bike\n"
     ]
    }
   ],
   "source": [
    "###### The first section of the story   \n",
    "print('You awake and look around \"Hey, I think I recognize this place\", you think to yourself. You realize \\\n",
    "that you are sitting down on something, you can not quite tell what, but you feel strangely awake.\\\n",
    "You turn to your right and see {} from {}. On your left, you see \\\n",
    "Donald Trump. You wonder where you are and how this all happened, but before you can think too much \\\n",
    "Trump turns to you and says '.format(protagonist,story),\\\n",
    "      trump_story.sentence_generate(3),\\\n",
    "        'Well that was weird you think to yourself. Shaking it off, you turn to {} who says, \\\n",
    "        \"Welcome to {}! We are excited to have you and your friend explore our \\\n",
    "        world. Before we start what do you want to bring with you on your \\\n",
    "        journey?'.format(protagonist,story),\\\n",
    "        \"'Please pick one from each category,' instructes {}.\".format(protagonist))\n",
    "print()## keep track of the options chosen\n",
    "while True:\n",
    "    print()\n",
    "    print(utility_items)\n",
    "    utility_item_chosen = input(\"Which item would you like?\")\n",
    "    if utility_item_chosen in utility_items:\n",
    "        break\n",
    "    else:\n",
    "        print('Please spell the word correctly without the quotes')\n",
    "while True:\n",
    "    print()\n",
    "    print(funny_items)\n",
    "    funny_item_chosen = input(\"Which of these would you like?\")\n",
    "    if funny_item_chosen in funny_items:\n",
    "        break\n",
    "    else:\n",
    "        print('Please spell the word correctly without the quotes')\n",
    "while True:\n",
    "    print()\n",
    "    print(transportation_items)\n",
    "    trans_item_chosen = input('Which of these would you like?')\n",
    "    if trans_item_chosen in transportation_items:\n",
    "        break\n",
    "    else:\n",
    "        print('Please spell the word correctly without the quotes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next    incorporating an item you have choosen.If you want to see the items you have, type items.items\n",
      "flashlight bike half-eaten-sandwich\n",
      "Please write a sentence for what you would like to do next    incorporating an item you have choosen.If you want to see the items you have, type items.i want to ride my bike after eating my sandwich.\n"
     ]
    }
   ],
   "source": [
    "#First choice by the user\n",
    "choice1=[]\n",
    "while True:\n",
    "    choice = input('Please write a sentence for what you would like to do next\\\n",
    "    incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "    if choice =='items':\n",
    "        print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "    else:\n",
    "        choice1.append(choice)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After each block of story, the sentence entered by the user will be used by an IR system (tf-idf with cosine similarity) to pick the  next part of the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    }
   ],
   "source": [
    "# the first section of possible texts for the story\n",
    "storychunk_one = place_of_story(1,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(2),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three) #protagonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"It is time to explore!\" you announce to hans . With that, you jump on your bike, put Trump on the handlebars, and start going. \"Wait!\" yells hans \"You are going to need this,\" she says handing you a king. What do you do next? '"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_one = TfidfVectorizer() \n",
    "tf_idf_storyone= tfidf_one.fit_transform(storychunk_one) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice1_tfidf = tfidf_one.transform(choice1) ## turn the user sentence into a vector\n",
    "cosine_sim_one = linear_kernel(tf_idf_storyone,choice1_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "re.sub(r'(\\t)','',storychunk_one[cosine_sim_one.argsort()[::-1][0]]) ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next     incorporating an item you have choosen.If you want to see the items you have, type items.ride my bike away\n"
     ]
    }
   ],
   "source": [
    "choice2=[]\n",
    "while True:\n",
    "    choice = input('Please write a sentence for what you would like to do next \\\n",
    "    incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "    if choice =='items':\n",
    "        print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "    else:\n",
    "        choice2.append(choice)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Feeling good about your self you decide that some fresh air would do you well.   You take your bike and start biking along the man with hans watching while Trump runs alongside. 'Be careful!' hans yells before noticing gretel also watching you. 'Not you again!' exclaims hans. ' O yes, I am here to make sure everyone is a little less comfortable' gretel says smiling. What should you do?\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the second section of possible texts for the story\n",
    "storychunk_two = place_of_story(2,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three) \n",
    "tfidf_two = TfidfVectorizer()  #create a model\n",
    "tf_idf_storytwo= tfidf_two.fit_transform(storychunk_two) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice2_tfidf = tfidf_two.transform(choice2) ## turn the user sentence into a vector\n",
    "cosine_sim_two = linear_kernel(tf_idf_storytwo,choice2_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "re.sub(r'(\\t)','',storychunk_two[cosine_sim_two.argsort()[::-1][0]]) ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next     incorporating an item you have choosen.If you want to see the items you have, type items.eat my half-eaten-sandwich\n"
     ]
    }
   ],
   "source": [
    "choice3=[]\n",
    "while True:\n",
    "    choice = input('Please write a sentence for what you would like to do next \\\n",
    "    incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "    if choice =='items':\n",
    "        print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "    else:\n",
    "        choice3.append(choice)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You quickly take out what is left of your half-eaten-sandwich and show it to hans.  \"Good,\" sayd hans, \"We can use this to pay off gretel and get you to the man\".   You wonder where that is, or who gretel is, but you follow hans. What should you do now?'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the third section of possible texts for the story\n",
    "storychunk_three = place_of_story(3,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(4),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three) \n",
    "\n",
    "tfidf_three = TfidfVectorizer()  #create a model\n",
    "tf_idf_storythree= tfidf_three.fit_transform(storychunk_three) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice3_tfidf = tfidf_three.transform(choice3) ## turn the user sentence into a vector\n",
    "cosine_sim_three = linear_kernel(tf_idf_storythree,choice3_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "third_section = re.sub(r'(\\t)','',storychunk_three[cosine_sim_three.argsort()[::-1][0]] )\n",
    "third_section ##return the story chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please write a sentence for what you would like to do next         incorporating an item you have choosen.If you want to see the items you have, type items.half-eaten-sandwich\n"
     ]
    }
   ],
   "source": [
    "if 'dead' in third_section:\n",
    "    print('You died with Trump by your side. Better luck next time!')\n",
    "elif 'died' in third_section:\n",
    "    print('You died with Trump by your side. Better luck next time!')\n",
    "else:\n",
    "    choice4=[]\n",
    "    while True:\n",
    "        choice = input('Please write a sentence for what you would like to do next \\\n",
    "        incorporating an item you have choosen.If you want to see the items you have, type items.')  \n",
    "        if choice =='items':\n",
    "            print(utility_item_chosen,trans_item_chosen,funny_item_chosen)\n",
    "        else:\n",
    "            choice4.append(choice)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \"Congratulations!\" says hans \"You defeated gretel and survived Grimms fairy tales. Best of luck in your future adventures\" '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The fourth chunck - Only go here if the user made it here\n",
    "storychunk_four = place_of_story(4,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(2),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story) \n",
    "\n",
    "tfidf_four = TfidfVectorizer()  #create a model\n",
    "tf_idf_storyfour= tfidf_four.fit_transform(storychunk_four) ##tf-idf on the possible story chunks in storychunk_one\n",
    "choice4_tfidf = tfidf_four.transform(choice4) ## turn the user sentence into a vector\n",
    "cosine_sim_four = linear_kernel(tf_idf_storyfour,choice4_tfidf).flatten() ## cosine similarity between the story chunks and user sentence\n",
    "fourth_section = re.sub(r'(\\t)','',storychunk_four[cosine_sim_four.argsort()[::-1][0]] )\n",
    "fourth_section ##return the story chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The secret to surviving is using the half eaten sandwich at the third story section :). Now, let us test the accuracy of the IR system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "> Accuracy\n",
    "\n",
    "- To evaluate our system, we want to look at the sentence entered by our users that contains an item they choose (i.e. bike) and pick the response that has that item. Since there is only one correct answer for each query, we will look at the average accuracy using each item over a number of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    }
   ],
   "source": [
    "test_chunk_one = place_of_story(1,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    }
   ],
   "source": [
    "test_chunk_two = place_of_story(2,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/DSCI6004-student/Final_Project/sentence_generator.py:68: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  generated_text.append(starting_chars[start_char_index])\n"
     ]
    }
   ],
   "source": [
    "test_chunk_three = place_of_story(3,protagonist,antagonist,place_one,language_one,\\\n",
    "                        trump_story.sentence_generate(3),place_two,\\\n",
    "                          single_noun_one,single_noun_two,plural_noun_one,plural_noun_two,verb_one,verb_two,verb_three,story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_test_one_queries = [['pocketknife'],\\\n",
    "                            ['I like to run with my pocketknife'],\\\n",
    "                            ['This is a flashy fun way to show how cool you are with friends pocketknife'],\\\n",
    "                           ['Do you know who I am that I love to watch Trump with my pocketknife?'],\\\n",
    "                           ['This is incredible!\\\n",
    "                           I love to carve wood and eat food with my own pocketknife even though you know Trump\\\n",
    "                           has a way with words!']]\n",
    "\n",
    "list_of_test_two_queries =[['half-eaten-sandwich'],\n",
    "                          ['I like to run around the town with my half-eaten-sandwich'],\n",
    "                          [\"Wow, he really has a way with words with your half-eaten-sandwich\"],\n",
    "                          ['asdf asdf sandwich asdfa'],\n",
    "                          ['This is lightsaber battle run fight half-eaten-sandwich']]\n",
    "\n",
    "list_of_test_three_queries = [['bike'],\n",
    "                             ['i like to ride my bicycle i like to ribe my bike'],\n",
    "                             ['run away to the furtherst point that you can with your bike'],\n",
    "                             ['looing at the moon and the stars and trump overhead you jump on the bike'],\n",
    "                             ['Running, jumping, biking, with your bike along side eating, swimming, walking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The acuracy is', 0.8, 'The query that failed was :', [['This is incredible!                           I love to carve wood and eat food with my own pocketknife even though you know Trump has a way with words!']])\n",
      "('The acuracy is', 1.0)\n",
      "('The acuracy is', 1.0)\n"
     ]
    }
   ],
   "source": [
    "#First chuck\n",
    "print(accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife'))\n",
    "txt,num_one,quertxt,query_one = accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife')\n",
    "q_one = TextBlob(query_one[0][0])\n",
    "len_query_one = sum(q_one.word_counts.values())\n",
    "total_avg_len_query_one = np.mean([sum(TextBlob(i[0][0]).word_counts.values()) for i in list_of_test_one_queries])\n",
    "#Second Chucnk\n",
    "print(accuracy_score_test(list_of_test_one_queries,test_chunk_two,'pocketknife'))\n",
    "txt_two,num_two,quertxt,query_two = accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife')\n",
    "q_two = TextBlob(query_two[0][0])\n",
    "len_query_two = sum(q_two.word_counts.values())\n",
    "#Third chunk\n",
    "print(accuracy_score_test(list_of_test_one_queries,test_chunk_three,'pocketknife'))\n",
    "txt_three,num_three,quertxt,query_three = accuracy_score_test(list_of_test_one_queries,test_chunk_one,'pocketknife')\n",
    "q_three = TextBlob(query_three[0][0])\n",
    "len_query_three = sum(q_three.word_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The acuracy is', 0.8, 'The query that failed was :', [['Wow, he really has a way with words with your half-eaten-sandwich']])\n",
      "('The acuracy is', 1.0)\n",
      "('The acuracy is', 1.0)\n"
     ]
    }
   ],
   "source": [
    "#First chuck\n",
    "print(accuracy_score_test(list_of_test_two_queries,test_chunk_one,'half-eaten-sandwich'))\n",
    "    \n",
    "#Second Chucnk\n",
    "print(accuracy_score_test(list_of_test_two_queries,test_chunk_two,'half-eaten-sandwich'))\n",
    "    \n",
    "#Third chunk\n",
    "print(accuracy_score_test(list_of_test_two_queries,test_chunk_three,'half-eaten-sandwich'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The acuracy is', 0.8, 'The query that failed was :', [['run away to the furtherst point that you can with your bike']])\n",
      "('The acuracy is', 0.4, 'The query that failed was :', [['i like to ride my bicycle i like to ribe my bike'], ['run away to the furtherst point that you can with your bike'], ['looing at the moon and the stars and trump overhead you jump on the bike']])\n",
      "('The acuracy is', 0.8, 'The query that failed was :', [['Running, jumping, biking, with your bike along side eating, swimming, walking']])\n"
     ]
    }
   ],
   "source": [
    "#First chuck\n",
    "print(accuracy_score_test(list_of_test_three_queries,test_chunk_one,'bike'))\n",
    "    \n",
    "#Second Chucnk\n",
    "print(accuracy_score_test(list_of_test_three_queries,test_chunk_two,'bike'))\n",
    "    \n",
    "#Third chunk\n",
    "print(accuracy_score_test(list_of_test_three_queries,test_chunk_three,'bike'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In general, our IR system works pretty well unless the query closely resembles a different story chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
