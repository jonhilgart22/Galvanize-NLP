{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Choose your own adventure story\n",
    "\n",
    "### First define the different stories available\n",
    "- Sherlock\n",
    "- Alice in Wonderland\n",
    "- Ulysses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from functools import reduce\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to a choose yur own adventure story! Below you will pick\n"
     ]
    }
   ],
   "source": [
    "print('Welcome to a choose yur own adventure story! Below you will pick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which story would you like to inhabit? You can choose Sherlock, Alice in Wonderland, or Ulysses.Sherlock\n"
     ]
    }
   ],
   "source": [
    "story_names = ['Sherlock','Alice in Wonderland','Ulysses']\n",
    "while True:\n",
    "    story = input(\"Which story would you like to inhabit? You can choose Sherlock, Alice in Wonderland, or Ulysses.\")\n",
    "    if story in story_names:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Open the appropriate story based upon the user input\n",
    "if story =='Alice in Wonderland':\n",
    "    with open(\"../corpora/alice_in_wonderland.txt\") as f:\n",
    "        text = f.read()\n",
    "elif story =='Sherlock':\n",
    "    with open(\"../corpora/sherlock_all.txt\") as f:\n",
    "        text = f.read()\n",
    "elif story =='Ulysses':\n",
    "    with open(\"../corpora/ulysses.txt\") as f:\n",
    "        text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Token the words, count the frequency of each token, and create a unigram, bigram, and trigram dictionary\n",
    "blob_text = TextBlob(text)\n",
    "text_tokens = blob_text.tokens\n",
    "text_counter_unigram = Counter(text_tokens)\n",
    "text_counter_bigram = Counter(nltk.bigrams(text_tokens))\n",
    "text_counter_trigram = Counter(nltk.trigrams(text_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prob_distribution(counter):\n",
    "    \"\"\"Return the probability based upon a counter dictionary\"\"\"\n",
    "    #increase by 100000 to use numpy random choice\n",
    "    return {k:value/sum(counter.values()) for k,value in counter.items()}\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# def product(iterable):\n",
    "#     \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "#     return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "# def prob_words(words):\n",
    "#     \"Probability of words, assuming each word is independent of others.\"\n",
    "#     return product(prob_distrubtion(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Probability distributions for different text combinations\n",
    "#This takes ~10 minutes to run\n",
    "prob_dist_unigram = prob_distribution(text_counter_unigram)\n",
    "prob_dist_bigram = prob_distribution(text_counter_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_dist_trigram = prob_distribution(text_counter_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cond_prob_word(end_word, first_word):\n",
    "    \"Conditional probability of word, given previous word.\"\n",
    "    bigram = (first_word , end_word)\n",
    "    if prob_dist_bigram[bigram] > 0 and prob_dist_unigram[first_word] > 0:\n",
    "        \n",
    "        return prob_dist_bigram[bigram] / prob_dist_unigram[first_word]\n",
    "    else: # Average the back-off value and zero.\n",
    "        return prob_dist_unigram[end_word] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cond_prob_trigram(start,middle,end):\n",
    "    \"\"\"Find the conditional probability of a trigram model given the two previous words.\"\"\"\n",
    "    trigram = (start ,middle , end)\n",
    "    bigram = ( start,middle)\n",
    "    if prob_dist_trigram[trigram] > 0 and prob_dist_bigram[bigram] > 0 and prob_dist_unigram[start] >0:\n",
    "        \n",
    "        return prob_dist_trigram[trigram] / prob_dist_bigram[bigram] ##return prob of trigram over first two words\n",
    "    elif prob_dist_bigram[bigram] > 0 and prob_dist_unigram[start] >0: # Back off to bigram model\n",
    "        return prob_dist_bigram[bigram] / prob_dist_unigram[start]\n",
    "    else: #back off to unigram model (three words)\n",
    "        return prob_dist_unigram[end]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.960262370247724e-06"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist_trigram[('I', 'saw', 'what')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023255999075869078"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_prob_trigram('I', 'saw', 'what')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence_generator(probability_dict_unigram, probability_dict_bigram,probability_dict_trigram, number_of_sentences):\n",
    "    \"\"\"Generate random sentences based upon the probabilities given the the probability_dict\"\"\"\n",
    "    number=0\n",
    "    generated_text=[]\n",
    "    character_counter = 0\n",
    "        \n",
    "    #Find starting words of sentences\n",
    "    starting_chars = [item[1]  for item in list(probability_dict_bigram.keys()) if item[0]==\".\"]\n",
    "    starting_chars_counter = Counter(starting_chars)\n",
    "    #print(starting_chars)\n",
    "    \n",
    "    #find list of unigram probabilities for starting characters\n",
    "    starting_prob = prob_distribution(starting_chars_counter)\n",
    "    \n",
    "    #Pick an initial starting character\n",
    "    start_char_index = np.random.choice([i for i in range(len(starting_chars))],1,p=list(starting_prob.values()))\n",
    "    generated_text.append(starting_chars[start_char_index])\n",
    "    print(generated_text,'generated text')\n",
    "    \n",
    "    while number !=number_of_sentences: #make sure we have this number of sentences\n",
    "      \n",
    "        print(generated_text,'generated text')\n",
    "        \n",
    "        if len(generated_text)<3:\n",
    "        \n",
    "            words_list = list(probability_dict_bigram.keys())\n",
    "            prev_character=generated_text[character_counter]\n",
    "\n",
    "            current_word_options = [i[1] for i in text_counter_bigram if i[0]==prev_character] #Find bigrams with prev char\n",
    "            print(current_word_options, ' current word options')\n",
    "\n",
    "            prob_bigram_list = []\n",
    "            for curr_word in current_word_options:\n",
    "                prob_bigram_list.append(cond_prob_word(curr_word,prev_character))\n",
    "\n",
    "            #print(prob_bigram_list, ' prob bigram')\n",
    "            print(sum(prob_bigram_list))\n",
    "\n",
    "            # weighted choice algorithm\n",
    "            # http://stackoverflow.com/questions/22722079/choosing-elements-from-python-list-based-on-probability\n",
    "            # 1) pick random number between 0 and 1\n",
    "            # 2) walk through the list, subtracting each item from your number as your go\n",
    "            # 3 ) when you go to 0 or below, pick the current item\n",
    "            weight = np.random.random()\n",
    "            print(weight,'weight')\n",
    "            bigram_word_index = 0\n",
    "\n",
    "            for index,prob in enumerate(prob_bigram_list):\n",
    "                weight -=prob\n",
    "                if weight <0:\n",
    "                    bigram_word_index=index\n",
    "\n",
    "            word = current_word_options[bigram_word_index]\n",
    "        \n",
    "            generated_text.append(word)\n",
    "            character_counter+=1 ## go to the next character\n",
    "            \n",
    "        elif len(generated_text)>2: ###trigram \n",
    "            \n",
    "            words_list = list(probability_dict_trigram.keys()) ## list of all trigram\n",
    "            first_character=generated_text[character_counter] # find the previous word (one index away)\n",
    "            second_character=generated_text[character_counter-1] #find the previous word\n",
    "            \n",
    "            current_triword_options= []\n",
    "            prob_trigram_list = [] #list of conditional probabilities\n",
    "            for i in text_counter_trigram:\n",
    "                if i[0]==first_character and i[1]==second_character:\n",
    "                    current_triword_options = i[2] #the current word to predict\n",
    "                    print(curr_word , 'current word')\n",
    "                    prob_trigram_list.append(cond_prob_trigram(curr_word[0],curr_word[1],curr_word[2]))\n",
    "                    \n",
    "            # tuple ('The', 'boy', 'went) i[0]=The, i[1]=boy, i[2]=went (we want to predict went)\n",
    "            print(current_triword_options, ' current word options')\n",
    "\n",
    "\n",
    "\n",
    "            #print(prob_bigram_list, ' prob bigram')\n",
    "            print(sum(prob_trigram_list))\n",
    "\n",
    "            # weighted choice algorithm\n",
    "            # http://stackoverflow.com/questions/22722079/choosing-elements-from-python-list-based-on-probability\n",
    "            # 1) pick random number between 0 and 1\n",
    "            # 2) walk through the list, subtracting each item from your number as your go\n",
    "            # 3 ) when you go to 0 or below, pick the current item\n",
    "            weight = np.random.random()\n",
    "            print(weight,'weight')\n",
    "            trigram_word_index = 0\n",
    "\n",
    "            for index,prob in enumerate(prob_trigram_list):\n",
    "                weight -=prob\n",
    "                if weight <0:\n",
    "                    try:\n",
    "                        word = current_triword_options[trigram_word_index]\n",
    "                    except:\n",
    "                        new_weight = np.random.random()\n",
    "                        \n",
    "                        \n",
    "                    trigram_word_index=index\n",
    "                    break\n",
    "            try: ##might not find a trigram\n",
    "                word = current_triword_options[trigram_word_index]\n",
    "            except: ##try a bigram\n",
    "                \n",
    "                word = current_word_options[trigram_word_index]\n",
    "                \n",
    "        \n",
    "            generated_text.append(word)\n",
    "            \n",
    "            character_counter+=1 ## go to the next character (skip characters due to trigram model)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if word ==\".\": ##end of the sentence\n",
    "            number+=1\n",
    "        \n",
    "        if character_counter==15:\n",
    "            break\n",
    "\n",
    "       \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counter_bigram[('boy','the')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cond_prob_word('the','man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhilgart/anaconda/envs/nlp/lib/python3.5/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['With'] generated text\n",
      "['With'] generated text\n",
      "['that', 'an', 'his', 'him', 'the', 'a', 'trembling', 'this', 'these', 'much', 'making', 'my', 'your', 'hardly']  current word options\n",
      "1.0000079601990053\n",
      "0.14149390848449417 weight\n",
      "['With', 'hardly'] generated text\n",
      "['tell', 'shut', 'have', 'out', 'imagine', 'served', 'spoken', 'flashed', 'yet', 'explain', 'reached', 'visible', 'consider', 'wander', 'pass', 'avoid', 'be', 'expect', 'noticed', 'said', 'take', 'looked', 'from', 'spoke', 'found', 'resist', 'see', 'believe', 'get', 'knows', 'a', 'safe', 'think', 'listened', 'knowing', 'finished']  current word options\n",
      "1.000007960199005\n",
      "0.16593479626485896 weight\n",
      "['With', 'hardly', 'finished'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.5112980623644757 weight\n",
      "['With', 'hardly', 'finished', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.6633964374523068 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.026140209751155385 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.5138597203056265 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.6551252720616954 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.9290331457554933 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.8914746763631074 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.4984474259112591 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.9456002897660356 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.07131908885407312 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.6868314077062708 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.6519879643225666 weight\n",
      "['With', 'hardly', 'finished', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell', 'tell'] generated text\n",
      "[]  current word options\n",
      "0\n",
      "0.7718281963311294 weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['With',\n",
       " 'hardly',\n",
       " 'finished',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell',\n",
       " 'tell']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generator(prob_dist_unigram,prob_dist_bigram,prob_dist_trigram,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [1,2,3,4,3,2,334234,2,2,3,3,4,4,3,2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coun_l = Counter(l)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.05555555555555555,\n",
       " 2: 0.4444444444444444,\n",
       " 3: 0.2777777777777778,\n",
       " 4: 0.16666666666666666,\n",
       " 334234: 0.05555555555555555}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distribution(coun_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.545593768033727"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [nlp]",
   "language": "python",
   "name": "Python [nlp]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
