{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Exercises: Named Entity Recognition (NER)\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aka, PERSON Classification\n",
    "----\n",
    "\n",
    "![](http://cdn4.teehunter.com/wp-content/uploads/2015/10/wheres-waldo-via-the-telegraph.jpg)\n",
    "\n",
    "__Where's Waldo in text?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Dr./NNP\n",
      "  (NE Brian/NNP Spiering/NNP)\n",
      "  works/VBZ\n",
      "  at/IN\n",
      "  (NE Galvanize/NNP)\n",
      "  //NNP\n",
      "  GalvanizeU/NNP\n",
      "  ,/,\n",
      "  powered/VBN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  (NE University/NNP)\n",
      "  of/IN\n",
      "  (NE New/NNP Haven/NNP)\n",
      "  ,/,\n",
      "  in/IN\n",
      "  (NE San/NNP Francisco/NNP)\n",
      "  ,/,\n",
      "  (NE California/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = \"Dr. Brian Spiering works at Galvanize / GalvanizeU, powered by the University of New Haven, in San Francisco, California.\"\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "print(nltk.ne_chunk(tagged,\n",
    "                    binary=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Change the function call so the output includes more details than just NE/Named Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should look something like this:\n",
    "```\n",
    "(S\n",
    "  Dr./NNP\n",
    "  (PERSON Brian/NNP Spiering/NNP)\n",
    "  works/VBZ\n",
    "  at/IN\n",
    "  (ORGANIZATION Galvanize/NNP)\n",
    "  //NNP\n",
    "  GalvanizeU/NNP\n",
    "  ,/,\n",
    "  powered/VBN\n",
    "  by/IN\n",
    "  the/DT\n",
    "  (ORGANIZATION University/NNP)\n",
    "  of/IN\n",
    "  (GPE New/NNP Haven/NNP)\n",
    "  ,/,\n",
    "  in/IN\n",
    "  (GPE San/NNP Francisco/NNP)\n",
    "  ,/,\n",
    "  (GPE California/NNP)\n",
    "  ./.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# How did the tagger do? \n",
    "# Is it surprising that it did so well?\n",
    "# If it missed a tag, why do you think it did?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's compare that to Standard's NER Tagger\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stanford NER (Named Entity Recognizer)](http://nlp.stanford.edu/software/CRF-NER.shtml) is one of the most popular Named Entity Recognition tools and implemented by Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Installing Java\n",
    "-----\n",
    "\n",
    "You're required to have Java working on your system because Java code is at the heart of the program. However, you do __not__ need to worry about the Java part because we provide the commands to compile and run the program.\n",
    "\n",
    "Assuming you are on a Mac... Make sure you have `homebrew` package manager installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.system(\"java -version\") == 32512: # Value for 'command not found'\n",
    "    os.system(\"brew doctor\")\n",
    "    os.system(\"brew update\")\n",
    "    os.system(\"brew install cask\")\n",
    "    os.system(\"brew cask install java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You might have run 'brew cask install java' in iTerm because installing Java sometimes requires a password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to play with Standford NER Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the [source code](http://www.nltk.org/_modules/nltk/tag/stanford.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It requires external dependencies including .jar (Java files) and classifers.\n",
    "\n",
    "We need to downloead those external dependencies. Let's grab a new-ish verison: `Stanford Named Entity Recognizer version 3.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = \"./stanford-ner-2014-06-16\"\n",
    "\n",
    "# If .jar file is not local, download it and set it up\n",
    "if not os.path.isfile(base_path+\"/stanford-ner.jar\"):\n",
    "    import urllib\n",
    "    import shutil\n",
    "    \n",
    "    url = \"http://nlp.stanford.edu/software/stanford-ner-2014-06-16.zip\"\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "    \n",
    "    os.system(\"brew tap homebrew/dupes\") # Install unzip prerequisites\n",
    "    os.system(\"brew install unzip\") # Install unzip\n",
    "    os.system(\"unzip \"+file_name) # Unzip\n",
    "    \n",
    "    # Now is time to hack...\n",
    "    # It turns out nltk hardcodes file names, thus we have to manually update the name\n",
    "    os.rename(base_path+\"/classifiers/english.all.3class.distsim.crf.ser.gz\", base_path+\"/classifiers/all.3class.distsim.crf.ser.gz\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to define our tagger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = StanfordNERTagger(base_path+'/classifiers/all.3class.distsim.crf.ser.gz',\n",
    "                       base_path+'/stanford-ner.jar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tag some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dr.', 'O'),\n",
       " ('Brian', 'PERSON'),\n",
       " ('Spiering', 'PERSON'),\n",
       " ('works', 'O'),\n",
       " ('at', 'O'),\n",
       " ('Galvanize', 'LOCATION'),\n",
       " ('', 'O'),\n",
       " ('GalvanizeU', 'O'),\n",
       " (',', 'O'),\n",
       " ('powered', 'O'),\n",
       " ('by', 'O'),\n",
       " ('the', 'O'),\n",
       " ('University', 'ORGANIZATION'),\n",
       " ('of', 'ORGANIZATION'),\n",
       " ('New', 'ORGANIZATION'),\n",
       " ('Haven', 'ORGANIZATION'),\n",
       " (',', 'O'),\n",
       " ('in', 'O'),\n",
       " ('San', 'LOCATION'),\n",
       " ('Francisco', 'LOCATION'),\n",
       " (',', 'O'),\n",
       " ('California', 'LOCATION'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.tag(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the 'O' mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Write code to tag all the 'O' tokens with more descriptive labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Click here for a hint.\n",
    "</summary>\n",
    "Conditionally combine both sets of tags\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Compare NER tags for ntlk default vs. Stanford. \n",
    "----\n",
    "\n",
    "Use \"History of The United States\" by Harles A. Beard and Mary R. Beard as the corpus.\n",
    "\n",
    "Load the file, then perform NER twice:\n",
    "\n",
    "1. First with ntlk default\n",
    "2. Second with Standford\n",
    "\n",
    "Compare performance on:\n",
    "\n",
    "1. Correctness\n",
    "2. Runtime\n",
    "\n",
    "Is there a pattern to the misses?\n",
    "\n",
    "Which tagger would you use? Why? When?\n",
    "\n",
    "Hints: \n",
    "- Start with a small sample to test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Challenge Exercises\n",
    "-----\n",
    "\n",
    "Try NER with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: load and setup spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-73b3aef93ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"My name is Brian\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_type_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t| \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "tokens = nlp(\"My name is Brian\")\n",
    "\n",
    "for token in tokens:\n",
    "    print(token, token.tag_, token.ent_type_, sep=\"\\t| \")\n",
    "\n",
    "# Output:\n",
    "\"\"\"\n",
    "My\t| PRP$\t| \n",
    "name\t| NN\t| \n",
    "is\t| VBZ\t| \n",
    "Brian\t| NNP\t| PERSON\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Repeat NER for the same text used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Benchmark spacy speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
