{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Exercise: Spell Correction\n",
    "====\n",
    "\n",
    "<img src=\"https://s-media-cache-ak0.pinimg.com/236x/af/22/72/af2272d2f2f749c196407d724005f232.jpg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "<img src=\"http://www.azquotes.com/picture-quotes/quote-simple-models-and-a-lot-of-data-trump-more-elaborate-models-based-on-less-data-peter-norvig-80-37-54.jpg\" style=\"width: 600px;\"/>\n",
    "\n",
    "Inspired by Peter Novig's [How to Do Things with Words in Python](http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "Spelling Correction Task\n",
    "----\n",
    "\n",
    "Given a word *w*, find the most likely correction *c* = `correct(`*w*`)`.\n",
    "\n",
    "__Approach:__ Try all candidate words *c* that are known words that are near *w*.  Choose the most likely one.\n",
    "\n",
    "How do we balance *near* and *likely*?\n",
    "\n",
    "For now, in a trivial way: always prefer nearer, but when there is a tie on nearness, use the word with the highest  count.  \n",
    "\n",
    "Measure nearness by *edit distance*: the minimum number of deletions, transpositions, insertions, or replacements of characters. By trial and error, we determine that going out to edit distance 2 will give us reasonable results.\n",
    "\n",
    "Then we can define `correct(`*w*`)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"Find the best spelling correction for this word.\"\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwise default to word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=counts.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The functions `known` and `edits0` are easy; and `edits2` is easy if we assume we have `edits1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words): ## This is a set\n",
    "    \"Return the subset of words that are actually in the dictionary.\"\n",
    "    return {word for word in words \n",
    "                if word in counts}\n",
    "\n",
    "def edits0(word): \n",
    "    \"Return all strings that are zero edits away from word (i.e., just word itself).\"\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    \"Return all strings that are two edits away from this word.\"\n",
    "    return {e2 for e1 in edits1(word) \n",
    "                for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'e', 'h', 'l', 'o', 'r', 't', 'u', 'w', 'y'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known('hello there how are you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `edits1(word)`: the set of candidate words that are one edit away. For example, given `\"wird\"`, this would include `\"weird\"` (inserting an `e`) and `\"word\"` (replacing a `i` with a `o`), and also `\"iwrd\"` (transposing `w` and `i`; then `known` can be used to filter this out of the set of final candidates). How could we get them?  One way is to *split* the original word in all possible places, each split forming a *pair* of words, `(a, b)`, before and after the place, and at each place, either delete, transpose, replace, or insert a letter:\n",
    "\n",
    "<table>\n",
    "  <tr><td> pairs: <td><tt> Ø+wird <td><tt> w+ird <td><tt> wi+rd <td><tt>wir+d<td><tt>wird+Ø<td><i>Notes:</i><tt> (<i>a</i>, <i>b</i>)</tt> pair</i>\n",
    "  <tr><td> deletions: <td><tt>Ø+ird<td><tt> w+rd<td><tt> wi+d<td><tt> wir+Ø<td><td><i>Delete first char of b</i>\n",
    "  <tr><td> transpositions: <td><tt>Ø+iwrd<td><tt> w+rid<td><tt> wi+dr</tt><td><td><td><i>Swap first two chars of b\n",
    "  <tr><td> replacements: <td><tt>Ø+?ird<td><tt> w+?rd<td><tt> wi+?d<td><tt> wir+?</tt><td><td><i>Replace char at start of b\n",
    "  <tr><td> insertions: <td><tt>Ø+?+wird<td><tt> w+?+ird<td><tt> wi+?+rd<td><tt> wir+?+d<td><tt> wird+?+Ø</tt><td><i>Insert char between a and b\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"Return all strings that are one edit away from this word.\"\n",
    "    #Creating all possible edits\n",
    "    pairs      = splits(word)\n",
    "    #print(pairs)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    #print(deletes,'delete')\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    #print(transposes,'transpose')\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    \n",
    "    #print(replaces,'replaces')\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    #print(inserts,'inserts')\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Load the alphabet from Standard Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "alphabet = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert alphabet == 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'wird'), ('w', 'ird'), ('wi', 'rd'), ('wir', 'd'), ('wird', '')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('wird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aello'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 'hello'\n",
    "''+'a'+l[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aello', 'bello', 'cello', 'dello', 'eello', 'fello', 'gello', 'hello', 'iello', 'jello', 'kello', 'lello', 'mello', 'nello', 'oello', 'pello', 'qello', 'rello', 'sello', 'tello', 'uello', 'vello', 'wello', 'xello', 'yello', 'zello', 'hallo', 'hbllo', 'hcllo', 'hdllo', 'hello', 'hfllo', 'hgllo', 'hhllo', 'hillo', 'hjllo', 'hkllo', 'hlllo', 'hmllo', 'hnllo', 'hollo', 'hpllo', 'hqllo', 'hrllo', 'hsllo', 'htllo', 'hullo', 'hvllo', 'hwllo', 'hxllo', 'hyllo', 'hzllo', 'healo', 'heblo', 'heclo', 'hedlo', 'heelo', 'heflo', 'heglo', 'hehlo', 'heilo', 'hejlo', 'heklo', 'hello', 'hemlo', 'henlo', 'heolo', 'heplo', 'heqlo', 'herlo', 'heslo', 'hetlo', 'heulo', 'hevlo', 'hewlo', 'hexlo', 'heylo', 'hezlo', 'helao', 'helbo', 'helco', 'heldo', 'heleo', 'helfo', 'helgo', 'helho', 'helio', 'heljo', 'helko', 'hello', 'helmo', 'helno', 'heloo', 'helpo', 'helqo', 'helro', 'helso', 'helto', 'heluo', 'helvo', 'helwo', 'helxo', 'helyo', 'helzo', 'hella', 'hellb', 'hellc', 'helld', 'helle', 'hellf', 'hellg', 'hellh', 'helli', 'hellj', 'hellk', 'helll', 'hellm', 'helln', 'hello', 'hellp', 'hellq', 'hellr', 'hells', 'hellt', 'hellu', 'hellv', 'hellw', 'hellx', 'helly', 'hellz'] replaces\n",
      "{'helko', 'herlo', 'hellro', 'helle', 'helglo', 'hellwo', 'rello', 'xello', 'fello', 'heclo', 'shello', 'hmllo', 'hella', 'helplo', 'nhello', 'aello', 'hlelo', 'helflo', 'hxllo', 'helloo', 'heqlo', 'helly', 'helulo', 'helloh', 'qello', 'heflo', 'hellqo', 'hlllo', 'helao', 'helfo', 'ghello', 'heello', 'hezllo', 'hellou', 'heolo', 'heloo', 'helilo', 'helpo', 'hellyo', 'hellop', 'hhello', 'hullo', 'helol', 'oello', 'hedlo', 'cello', 'hvllo', 'hfllo', 'hepllo', 'hevlo', 'hellk', 'hfello', 'helvlo', 'hellho', 'hellno', 'hellq', 'helqo', 'heltlo', 'helslo', 'heilo', 'fhello', 'hellxo', 'helloe', 'hellow', 'hkello', 'hellom', 'yhello', 'hpllo', 'heslo', 'hrllo', 'hhllo', 'heblo', 'zello', 'hellu', 'hrello', 'hvello', 'hellok', 'helln', 'healo', 'hellvo', 'hjello', 'helmo', 'jello', 'hecllo', 'helho', 'helgo', 'hbllo', 'ohello', 'whello', 'eello', 'hlello', 'hellon', 'nello', 'hllo', 'hellso', 'hyllo', 'hellx', 'tello', 'rhello', 'hellv', 'lello', 'chello', 'hedllo', 'helll', 'hellg', 'hkllo', 'hzllo', 'ehello', 'hnello', 'heyllo', 'herllo', 'helolo', 'helwo', 'helloy', 'hwllo', 'hellf', 'khello', 'helelo', 'bhello', 'helloi', 'heldlo', 'yello', 'mello', 'hemlo', 'heplo', 'hgllo', 'heljo', 'hellio', 'helzlo', 'hellko', 'hello', 'hjllo', 'heylo', 'heulo', 'hellc', 'hellob', 'hxello', 'hellb', 'helnlo', 'helleo', 'hnllo', 'hellm', 'helxo', 'hellov', 'helklo', 'hellh', 'hells', 'heallo', 'qhello', 'hgello', 'hyello', 'uello', 'helluo', 'helloj', 'bello', 'hollo', 'hpello', 'helso', 'helloa', 'helto', 'helmlo', 'hellmo', 'helio', 'hellp', 'hetllo', 'helloc', 'hsllo', 'helwlo', 'thello', 'phello', 'hqello', 'vello', 'htllo', 'hewllo', 'helxlo', 'hzello', 'helhlo', 'helclo', 'heluo', 'mhello', 'helllo', 'hesllo', 'hellz', 'hwello', 'heullo', 'hewlo', 'helloq', 'heleo', 'helvo', 'hell', 'hekllo', 'hoello', 'helbo', 'hcello', 'hellzo', 'heldo', 'hmello', 'helro', 'hellt', 'pello', 'hebllo', 'helylo', 'hellpo', 'hellod', 'heglo', 'heklo', 'hexllo', 'helloz', 'htello', 'hellao', 'hellco', 'hdllo', 'hehlo', 'heollo', 'henlo', 'hellox', 'uhello', 'helqlo', 'haello', 'helldo', 'ihello', 'hehllo', 'dhello', 'hellto', 'hsello', 'hcllo', 'zhello', 'hellbo', 'wello', 'helo', 'heelo', 'gello', 'hemllo', 'helblo', 'helljo', 'hqllo', 'hellot', 'dello', 'sello', 'hellor', 'ello', 'hellw', 'xhello', 'hiello', 'hellol', 'hegllo', 'helno', 'hejllo', 'hejlo', 'hellgo', 'helzo', 'helli', 'helyo', 'hellj', 'hellof', 'ehllo', 'heqllo', 'heljlo', 'hdello', 'helrlo', 'hellfo', 'iello', 'hetlo', 'helco', 'hevllo', 'ahello', 'hbello', 'hellog', 'hillo', 'hezlo', 'vhello', 'henllo', 'kello', 'heillo', 'hefllo', 'jhello', 'lhello', 'helalo', 'hexlo', 'hallo', 'helld', 'hellr', 'huello', 'hellos'}\n"
     ]
    }
   ],
   "source": [
    "print(edits1('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,254\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\".format(len(edits2('wird'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Setup common functions and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../../corpora/shakespeare_all.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = tokens(text)\n",
    "counts = Counter(words)\n",
    "#counts.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Back to spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_uncorrected = 'Speling errurs in somethink. Whutever; unusuel misteakes everyware?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG Token,  Corrected Token\n",
      "\n",
      "('speling', 'seeling')\n",
      "('errurs', 'errors')\n",
      "('in', 'in')\n",
      "('somethink', 'something')\n",
      "('whutever', 'whatever')\n",
      "('unusuel', 'unusual')\n",
      "('misteakes', 'mistakes')\n",
      "('everyware', 'everywhere')\n"
     ]
    }
   ],
   "source": [
    "phrase_corrected = map(correct, tokens(phrase_uncorrected))\n",
    "\n",
    "print(\"OG Token, \", \"Corrected Token\", end=\"\\n\\n\")\n",
    "print(*zip(tokens(phrase_uncorrected), \n",
    "           phrase_corrected), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Let's return a better formated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    \"Correct all the words within a text, returning the corrected text.\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "def correct_match(match):\n",
    "    \"Spell-correct word in match, and preserve proper upper/lower/title case.\"\n",
    "    #print(match,'match')\n",
    "    word = match.group() #this is a capture group for regular expresion\n",
    "    #print(word,'word')\n",
    "    #print(case_of(word)(correct(word.lower())))\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "def case_of(text):\n",
    "    \"Return the case-function appropriate for text: upper, lower, title, or just str.\"\n",
    "    #going through letter by letter\n",
    "    return (str.upper if text.isupper() else\n",
    "            str.lower if text.islower() else\n",
    "            str.title if text.istitle() else\n",
    "            str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our best guess for misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speling errurs in somethink. Whutever; unusuel misteakes everyware?\n",
      "Speling erreurs in somethin. Whatever; unusual mistakes everyway?\n"
     ]
    }
   ],
   "source": [
    "print(phrase_uncorrected)\n",
    "print(correct_text(phrase_uncorrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STRING'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'StrIng'\n",
    "p.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audiance sayzs: spealling is difffucult...\n",
      "Audience says: spelling is difficult...\n"
     ]
    }
   ],
   "source": [
    "phrase_uncorrected_2 = 'Audiance sayzs: spealling is difffucult...'\n",
    "print(phrase_uncorrected_2)\n",
    "print(correct_text(phrase_uncorrected_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase_harder = \"the elegant lady entered the room\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the element lady entered the room\n"
     ]
    }
   ],
   "source": [
    "print(correct_text(correct_text(phase_harder))) # Yikes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn.meme.am/cache/instances/folder5/500x/66510005.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Improve spellchecker with MOAR DATA. Load and use unigram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../corpora/unigram_word_counts.txt') as f:\n",
    "    unigram = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-cc9c2e73574f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t|\\s'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munigram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathanhilgart/anaconda/envs/nlp/lib/python3.5/re.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     of the list.\"\"\"\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "unigram = re.split('\\t|\\s',unigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666667"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_dict = {unigram[i-1]:unigram[i] for i in range(1,len(unigram))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23135851162'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dict['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = unigram_dict #this will redefine your corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the elegant lady entered the room\n"
     ]
    }
   ],
   "source": [
    "phase_harder = \"the elegant lady entered the room\"\n",
    "print(correct_text(correct_text(phase_harder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert phase_harder == correct_text(correct_text(phase_harder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you wrote lament, elicit, but you meant elegant\n"
     ]
    }
   ],
   "source": [
    "phase_haderest = \"you wrote elagent, elligit, but you meant elegant\"\n",
    "print(correct_text(correct_text(phase_haderest))) # Better but not great, yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Load common spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../../corpora/spell_errors.txt') as t:\n",
    "    spelling = t.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raining: rainning, raning\\nwritings: writtings\\ndisparagingly: disparingly\\nyellow:'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spelling[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spelling = re.split('\\n|:',spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spelling = [item.replace('_',' ') for item in spelling]\n",
    "spelling = [item.strip(' ') for item in spelling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at least\n"
     ]
    }
   ],
   "source": [
    "for item in spelling:\n",
    "    if item == 'at least':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spell_errors = {spelling[i-1]:spelling[i].split(', ') for i in range(1,len(spelling))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atleast']"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_errors['at least']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atleast']"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_errors['at least']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert spell_errors['raining'] == ['rainning', 'raning']\n",
    "assert spell_errors['at least'] == ['atleast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Rewrite \"correct\" function to use common errors if applicable otherwise default to old methdod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    for k,v in spell_errors.items():\n",
    "        if text in v:\n",
    "            return k\n",
    "    \n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=counts.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert correct_text(\"elagent\") == \"elegant\"\n",
    "assert correct_text(\"elligit\") == \"elegant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elegant'"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text(\"elligit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['elagent' in spell_errors['elegant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake = {'hello':['hi','bye']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [nlp]",
   "language": "python",
   "name": "Python [nlp]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
