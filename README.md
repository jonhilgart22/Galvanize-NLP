GalvanizeU-University of New Haven <br> Master of Science in Data Science <br> DSCI-6004: Unstructured Data and Natural Language Processing <br> October 24 - December 16, 2016
----

<img src="https://pbs.twimg.com/media/BrPvG7wCMAAk6Qh.png" alt="GO FIND IMAGE" align="middle" style="width: 350px;"/>

Table of Contents:
----
- Logistics
- Course Description
- Class Structure
- Course Requirements
- Grades
- Resources
- [Course Schedule](#course-schedule)

----
Logistics:
----
__Instructor:__ Brian Spiering [brian.spiering@galvanize.com](mailto:brian.spiering@galvanize.com)  
__Office Hours:__ Wednesday 11a-12n & By Appointment  

__Data-Scientist-in-Residence:__ [Maneesh Guta](mailto:maneesh.gupta@galvanize.com)  

__Class Location:__ 44 Tehama St, 309 classroom, San Francisco, CA  <br>
__Class Days/Times:__ 9a-10:20a Monday, Tuesday, Thursday, Friday <br>
__Lab Days/Times:__ 10:30a-12n Monday, Tuesday, Thursday, Friday <br>

__Communication:__ [Slack Channel](https://gstudent.slack.com/archives/gu4_sf_nlp)

----
Course Description
----
This course covers the fundamental concepts and algorithms in natural language processing (NLP). The goal is to process and understand text using statistical modeling and programming.

This course will start with basic text processing techniques (such as regular expressions and handling text encodings) and then cover advanced techniques (text classification and topic modeling). Finally, finish the course by introducing to Deep Learning with the word2vec algorithm. Along the way we will touch upon text mining, information retrieval, and computational linguistics.

This is course is a "buffet" format, a sample of everything but you get full on any one topic. People get PhD in each of these topics. __Remember__ - a little bit of knowledge goes a long way.

By the end of the course, you should be able to:  
----

1. Apply fundamental NLP concepts and algorithms to solve real-world problems
1. Write efficient code to process text data
1. Deploy a chat bot
1. Build an information retrieval system
1. Classify text to perform sentiment analysis
1. Cluster text to perform topic modeling 
1. Create and use vector representations of words with word2vec
1. Build an end-to-end system to model meaning in text

Out of Scope
----
- Theory. We are only going to cover applied parts of NLP, aka tips n' tricks for getting stuff done.
- Grammar. It sucks but is a very powerful way of understanding language (thank me later).
- Non-English languages. I ❤️ other languages, and they are very important to NLP. There is just enough not time!
- Natural Language Understanding (NLU). Finding "meaning" in text. We'll spend most of our time focused on lower levels of processing.
- Natural Language Generation (NLG). We'll only going to briefly touch on how to programmatically create text.
- Speech. In the last couple of years, speech-based language processing has advanced greatly. For this class, we'll assume audio waves have been digitized into text.

Prerequisites
----
A curiosity about how to computationally approach natural language and...  
Successful completion of:  

- DSCI-6001: Mathematics for Data Scientists   
- DSCI-6002: Data Exploration, Feature Engineering, and Statistics for Data Scientists  

----
Resources
----

### Required:

__None.__ Right now there is no single resource that covers current applied methods for NLP.

### Optional:
- Book: [Natural Language Processing with Python](http://www.nltk.org/book/) by Steven Bird, Ewan Klein, and Edward Loper. One of the only books on NLP. The 1st edition is out-of-date and the 2nd edition has been abandoned. It also covers Python fundamentals.
- Coursera Course: [Natural Language Processing](https://www.coursera.org/learn/natural-language-processing) Video course on fundamentals.
- [Taming Text](https://www.manning.com/books/taming-text) by Ingersoll, Morton, and Farris. An accessible introduction to applying NLP to real-world problems.
- [Introduction to Information Retrieval](http://nlp.stanford.edu/IR-book/html/htmledition/irbook.html) by Manning, Raghavan, and Schütze. Learn how to make your own Google-style search engine.

----
Class Structure
----

This course is an "active" learning environment. You'll learn through doing. The focus will be applying concepts to data through programming.

Before class you will complete preparation materials (e.g., watch videos, read chapters, and complete workbooks). All preparation materials should be covered prior to the start of each class session. They are __always required__ unless explicitly labeled as optional. These materials will be resource for factual knowledge. I (Brian) will not be delivering traditional lectures. You are expected to be familiar with the basic concepts and technical jargon by the start of class.

In-class time is precious - We'll reserve it for discussion, presenting complex material, answering questions, and working on exercises.  

Typical class structure:

1. On Your Own (OYO) activity
1. Review and discussion of today's topic
1. RAT (Readiness Assessment Test)
1. Exercises

### Complete On Your Own (OYO) activity

OYO activity is a creative activity to help you to integrate and apply the the preparation materials.

### Review and discussion of prepration materials

We'll review the most important concepts from the preparation materials. Also cover any complex materials.

### RATs

The Readiness Assessment Tests (RATs) are intended to test your understanding of the materials presented thus far in the course. This includes recent preparation material and items from previous classes. There are 3 parts: individual, small-group, and class

1. Each student will answered all the questions on the RAT individually.
2. Then the class will split into teams of 3-4. Each team will answer the same questions again, the goal is to reach consensus. This is an opportunity for peer-to-peer instruction which is often more effective than lectures!
3. Finally, the answers to the questions will be gone over by the class, hopefully resolving any final misunderstandings before proceeding with the exercises.

### Exercises

The RATs are meant to assess the first three levels of [Bloom's Taxonomy](http://en.wikipedia.org/wiki/Bloom's_taxonomy#Cognitive): knowledge, comprehension, and analysis. The project work is meant to develop the latter three levels: analysis, synthesis, and evaluation. Students will separate into two (or threes) for "pair programming". These exercises may involve a series of short questions, single day projects, or multi-day projects.

### Miscellaneous

[Pair programming](https://en.wikipedia.org/wiki/Pair_programming). "Pairing" is where two programmers are working on the same code at the same time. It is a great way to improve as programmer and solve problems. One acts as the "driver", the other as the "navigator". The driver types and the navigator helps. For example, the navigator might name variables or look up documentation. Pairs will change every class.

Project Presentations. Presentation are one way to demonstrate your learning, but more importantly it is practice for organizing and communicating your work and ideas. The presentations will function similar to code reviews in-front of your peers and instructors, who will function like Senior Developers. The purpose of students presenting work is two-fold:    

1. All students will learn from all exercises, whether or not they had time to complete them in class.  
2. Students will get to see alternative approaches to the exercises they did complete.

----
Grades
----

| Item | Weight  |  
|:-------:|:------:|
| Mastery Tracker | 25% |  
| Participation | 25% |  
| Final Project | 50% |

The expected grade for this class is a B+. Getting an A- or above requires completion of the Mastery Tracker, high level participation, and a stellar final project.

### Mastery Tracking

Mastery Tracking is a tool to provide feedback student learning. Standards are the core-competencies of MSDS graduates - the knowledge, skills, and habits every student should possess by time they graduate. Standards are measurable, student-focused outcomes that state what students are expected to be able to do by the end of the course. Students who are below ‘mastery’ on a standard are expected to continue practicing said standard (with the instructor's guidance) until they reach mastery. What matters is that students eventually learn the material, not how many attempts it takes to get there. The Instructor and Data Scientist in Residence are available to offer feedback and help guide everyone on their mastery journey.

Mastery Tracking uses a 4-point scale. Every student is expected to achieve 3 or above (Mastery) across all Standards by the end of the course. 1s and 2s indicate areas where students need further practice and/or interventions to reach mastery.

4 pt Scale:

0 = Has not been covered  
1 = Falling far below mastery - Meeting none of the success criteria or has egregious errors  
2 = Approaching mastery - Meeting some of the success criteria  
3 = Mastery - Meeting all of the success criteria  
4 = Exceeding mastery - Truly exceeding expectations and demonstrating proficiency at a higher level of rigor  

We will be using Galvanize's Learning Management System (LMS) which can be found at [learn.galvanize.com](https://learn.galvanize.com).

### Participation
You must also show up prepared. Each person is important to the dynamic of the class, and therefore students are required to participate in class activities. Expect to be "cold called". I call on students at random not to put you on the spot but to keep you engaged in the material at all times.

Attendance is mandatory. It is the responsibility of the student to attend all classes. If you have to miss class, due to sickness or other circumstances, please notify your instructor by Slack in advance. Supporting documents (doctor’s notes) should accompany absences due to sickness. Each excused absences beyond 2 or any unexcused absences will result in lowering your __overall course grade by ⅓ of an entire letter grade__ (A->A-, A->B+). It is at the instructor’s discretion to deny any absences or to allow students to make-up assignments, exams, etc. resulted from any absences.

Individual participation notes will be shared via Google Drive.

### Final Project

Details will be covered in a future class (mostly likely tomorrow).

----
Course Requirements
----

### Electronic Device Policy
Cell phones can be highly disruptive to the class environment. Please silence these devices. In the event of the need to use electronic devices during an person emergency, please step out of the classroom.

### Academic Integrity
The University of New Haven is an academic community based on the principles of honesty, trust, fairness, respect, and responsibility. Academic integrity is a core University value which ensures respect for the academic reputation of the University, its students, faculty and staff, and the degrees it confers.

The University expects that all students will learn in an environment where they work independently in the pursuit of knowledge, conduct themselves in an honest and ethical manner and respect the intellectual work of others. Each member of the University community has a responsibility to be familiar with the definitions contained in, and adhere to, the Academic Integrity Policy. Violations of the Academic Integrity Policy include, but are not limited to:

- Cheating -- i.e. Don't read off of your neighbors exams
- Collusion -- Group work is encouraged except on evaluative exams. When working together (on exercises, etc.), acknowledgment of collaboration is required.
- Plagiarism -- Reusing code presented in labs and lectures is expected, but copying someone else's solution to a problem is a form of plagiarism (even if you change the formatting or variable names).
- Facilitating academic dishonesty

Students who are dishonest in any class assignment or exam will receive an "F" in this course. More information regarding UNH’s official academic integrity policies are outlined in [here](http://www.newhaven.edu/334887.pdf).

----
Course Schedule
----

1. NLP FUNdamentals
    1. Welcome and NLP Overview
    2. Text Processing & Regular Expressions I
    3. Regular Expressions II
    4. Segmenting, Tokenizing, & Stemming
2. Language Modeling
    1. Text Encoding
    2. Edit Distance
    3. Language Modeling I
    4. Language Modeling II
3. Doing Useful Stuff with NLP
    1. Spelling Correction
    2. Word Tagging
    3. Named Entity Recognition (NER) (Wednesday)
    4. Review / Project Check-in (Thursday)
4. Information Retrieval
    1. Information Retrieval I 
    2. Information Retrieval II
    3. Information Retrieval Project Worksession & Presentations  
    4. Chatbots I 
5. Text Classification
    1. Chatbots II
    2. Text Classification: Naïve Bayes
    3. Holiday 🦃 🍗 😴
    4. Holiday 🦃 🍗 😴
6. Topic Modeling
    1. Text Classification: Sentiment Analysis
    2. Topic Modeling: Non-negative matrix factorization (NMF)
    3. Topic Modeling: Latent Dirichlet allocation (LDA)
    4. Topic Modeling Project Project Worksession & Presentations
7. Word2Vec
    1. Word2Vec
    2. Doc2Vec
    3. __Optional__: Worksession (Wednesday)
    4. Everything2Vec / Word2Vec Project Worksession & Presentations  (Thursday)
8. Final Presentations
    1. The Future of NLP & Guest Speaker 
    2. Review (Remember: You will lose tomorrow as a work day to capstone pitches)
    3. Final Project Presentations
    4. Final Project Presentations
